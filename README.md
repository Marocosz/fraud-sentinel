# üõ°Ô∏è Fraud Sentinel - Advanced Fraud Detection System

**Fraud Sentinel** √© um sistema de detec√ß√£o de fraudes banc√°rias end-to-end, projetado para lidar com datasets extremamente desbalanceados (onde fraudes representam ~1% ou menos dos dados). O projeto foca em rigor estat√≠stico, reprodutibilidade e utiliza√ß√£o de algoritmos de estado da arte para minimizar perdas financeiras.

---

## üî¨ Hist√≥rico de Experimentos (Log)

Esta se√ß√£o documenta cronologicamente todos os experimentos realizados para alcan√ßar o modelo final, detalhando a evolu√ß√£o das estrat√©gias de balanceamento e otimiza√ß√£o.

### üß™ Experimento 1: Baseline com SMOTE Agressivo (Ratio 0.5)

_Nesta fase inicial, utilizamos SMOTE com ratio 0.5 e Class Weights='balanced'. O resultado mostrou alto Recall mas baix√≠ssima Precis√£o (muitos falsos positivos)._

| Run ID            | Modelo              | ROC-AUC | F1-Score (Classe 1) | Precision (Classe 1) | Recall (Classe 1) | Estrat√©gia                          |
| :---------------- | :------------------ | :------ | :------------------ | :------------------- | :---------------- | :---------------------------------- |
| `20260217_201608` | **XGBoost**         | 0.8848  | 0.0582              | 3.0%                 | **89.2%**         | SMOTE 0.5 + Scale Pos Weight 90     |
| `20260217_193856` | Random Forest       | 0.8754  | 0.1868              | 13.9%                | 28.5%             | SMOTE 0.5 + Class Weight 'balanced' |
| `20260217_191942` | Logistic Regression | 0.8746  | 0.1211              | 6.7%                 | 65.3%             | SMOTE 0.5 + Class Weight 'balanced' |
| `20260217_192103` | Decision Tree       | 0.8315  | 0.1322              | 7.7%                 | 46.4%             | SMOTE 0.5 + Class Weight 'balanced' |

> **Diagn√≥stico:** O uso combinado de SMOTE agressivo (0.5) com pesos de classe gerou uma "Dupla Penaliza√ß√£o", fazendo os modelos superestimarem o risco e gerarem excesso de alarmes falsos (Precision < 15%).

---

### üß™ Experimento 2: SMOTE Reduzido (Ratio 0.3-0.4) + Threshold Tuning

_Tentativa de corre√ß√£o reduzindo a gera√ß√£o de dados sint√©ticos e ajustando o limiar de decis√£o._

| Run ID            | Modelo              | ROC-AUC | F1-Score (Classe 1) | Precision (Classe 1) | Recall (Classe 1) | Threshold Otimizado |
| :---------------- | :------------------ | :------ | :------------------ | :------------------- | :---------------- | :------------------ |
| `20260217_205713` | **Random Forest**   | 0.8795  | 0.1709              | 19.7%                | 15.1%             | > 0.34              |
| `20260217_204326` | Logistic Regression | 0.8746  | 0.1537              | 8.9%                 | 55.0%             | > 0.79              |
| `20260217_204434` | Decision Tree       | 0.8266  | 0.1607              | 12.8%                | 21.4%             | > 0.50              |

> **Diagn√≥stico:** A precis√£o melhorou marginalmente, mas o Recall caiu drasticamente em alguns casos. A estrat√©gia de SMOTE ainda parecia introduzir ru√≠do.

---

### üß™ Experimento 3: Cost-Sensitive Learning (Sem SMOTE) - **FINAL**

_Removemos o SMOTE completamente e focamos puramente em Pesos de Classe (Class Weights) combinados com Otimiza√ß√£o de Threshold via F1-Score._

| Run ID            | Modelo              | ROC-AUC    | F1-Score (Macro) | Precision (Weighted) | Recall (Weighted) | Threshold Otimizado |
| :---------------- | :------------------ | :--------- | :--------------- | :------------------- | :---------------- | :------------------ |
| `20260217_212224` | **XGBoost üèÜ**      | **0.8806** | **0.5753**       | **0.9822**           | **0.9869**        | **> 0.26**          |
| -                 | Random Forest       | 0.8795     | 0.5814           | 0.9818               | 0.9839            | > 0.34              |
| -                 | Logistic Regression | 0.8746     | 0.5594           | 0.9847               | 0.9332            | > 0.79              |

> **Conclus√£o:** Esta foi a estrat√©gia vencedora. O XGBoost sem SMOTE, mas com `scale_pos_weight=90` e corte de decis√£o em `0.26`, entregou o melhor equil√≠brio operacional.

---

## üöÄ Resultados dos Modelos (Benchmark Final)

Ap√≥s rigorosa otimiza√ß√£o de hiperpar√¢metros e ajuste fino de limiares de decis√£o (Threshold Tuning), os modelos atingiram os seguintes resultados nos dados de valida√ß√£o:

| Modelo                     | ROC-AUC    | F1-Score   | Observa√ß√£o Cr√≠tica                                                                               |
| :------------------------- | :--------- | :--------- | :----------------------------------------------------------------------------------------------- |
| **ü•á XGBoost**             | **0.8806** | **0.5753** | O campe√£o indiscut√≠vel. Melhor equil√≠brio entre pegar fraudes e n√£o bloquear clientes leg√≠timos. |
| **ü•à Random Forest**       | 0.8795     | 0.5814     | Desempenho s√≥lido, muito pr√≥ximo do XGBoost, ligeiramente mais conservador.                      |
| **ü•â Logistic Regression** | 0.8746     | 0.5594     | Excelente baseline. Surpreendentemente robusto para um modelo linear simples.                    |
| **Decision Tree**          | 0.8266     | 0.5741     | O mais fraco, propenso a overfitting, mas √∫til para explicar regras simples.                     |

> **Nota T√©cnica:** O F1-Score pode parecer "baixo" (0.57), mas em detec√ß√£o de fraude (onde a classe positiva √© 1%), esse valor √© **excelente**. Um modelo aleat√≥rio teria F1 pr√≥ximo de 0.02.

---

## üèÜ Modelos Treinados e Artefatos

Todos os modelos treinados s√£o salvos automaticamente na pasta `models/` com versionamento e logs de execu√ß√£o.

### 1. XGBoost (O Campe√£o)

- **Arquivo do Modelo:** `models/xgb_best_model.pkl`
- **Melhores Hiperpar√¢metros:**
  - `learning_rate`: 0.1 (Aprendizado cauteloso)
  - `max_depth`: 3 (√Årvores rasas para evitar overfitting)
  - `n_estimators`: 200 (N√∫mero robusto de √°rvores)
  - `scale_pos_weight`: 90 (Peso 90:1 para compensar o desbalanceamento)
- **Threshold Otimizado:** `> 0.26` (Qualquer transa√ß√£o com probabilidade acima de 26% √© classificada como fraude para maximizar o lucro).

### 2. Random Forest

- **Arquivo do Modelo:** `models/rf_best_model.pkl`
- **Melhores Hiperpar√¢metros:**
  - `n_estimators`: 200
  - `max_depth`: 20 (√Årvores profundas)
  - `class_weight`: 'balanced'
- **Threshold Otimizado:** `> 0.34`

### 3. Logistic Regression

- **Arquivo do Modelo:** `models/logreg_best_model.pkl`
- **Melhores Hiperpar√¢metros:**
  - `C`: 0.01 (Alta regulariza√ß√£o para generaliza√ß√£o)
  - `penalty`: 'l2' (Ridge Regression)
  - `class_weight`: 'balanced'
- **Threshold Otimizado:** `> 0.79` (Muito exigente, s√≥ bloqueia se tiver quase certeza absoluta).

---

## üéØ Objetivo do Projeto

O objetivo principal √© desenvolver um modelo preditivo capaz de distinguir transa√ß√µes leg√≠timas de fraudulentas com alta precis√£o, priorizando a **maximiza√ß√£o do Recall** (detectar o m√°ximo de fraudes poss√≠vel) sem prejudicar excessivamente a experi√™ncia do usu√°rio (controle de Falsos Positivos via Precision).

O sistema segue o ciclo de vida padr√£o da Ci√™ncia de Dados (CRISP-DM), com √™nfase em:

1.  **Entendimento Profundo dos Dados**: Testes de hip√≥tese e valida√ß√£o estat√≠stica.
2.  **Engenharia de Features**: Sele√ß√£o baseada em ganho de informa√ß√£o (Mutual Information).
3.  **Benchmarking Rigoroso**: Valida√ß√£o cruzada estratificada para evitar _overfitting_.

---

## üõ†Ô∏è M√≥dulo 0: Engenharia de Dados (`make_dataset.py`)

A base de tudo. Este script n√£o apenas "corta" os dados, ele prepara o terreno para que modelos de IA rodem sem estourar a mem√≥ria RAM.

### ‚öôÔ∏è Funcionalidades Chave

- **Otimiza√ß√£o de Mem√≥ria (Downcasting)**:
  - Converte automaticamente tipos pesados (`float64`, `int64`) para vers√µes leves (`float32`, `int8`) sem perder informa√ß√£o.
  - _Resultado:_ Redu√ß√£o significativa no tamanho do dataset em mem√≥ria, cr√≠tico para processar milh√µes de transa√ß√µes de fraude.
- **Split Estratificado**:
  - Garante matematicamente que a propor√ß√£o de fraudes (~1%) seja id√™ntica nos dados de Treino e Teste. Evita que o Teste fique "f√°cil demais" ou "dif√≠cil demais" por sorte.
- **Valida√ß√£o de Schema**:
  - Verifica se as colunas cr√≠ticas (Target) existem antes de prosseguir, evitando erros silenciosos no futuro.

### üìÇ Artefatos Gerados

Ao final da execu√ß√£o, a pasta `data/processed/` conter√° os dados prontos para consumo pelos modelos:

- **`X_train.csv`**: Features (vari√°veis explicativas) para o treinamento dos modelos.
- **`y_train.csv`**: Target (alvo: 0 ou 1) correspondente ao treino.
- **`X_test.csv`**: Features reservadas (blind set) para valida√ß√£o final. NUNCA usadas no treino.
- **`y_test.csv`**: Target correspondente ao teste.

---

## üìä M√≥dulo 1: An√°lise Explorat√≥ria Automatizada (`generate_eda_report.py`)

Este script funciona como um "Raio-X" completo dos dados. Ao inv√©s de apenas plotar gr√°ficos aleat√≥rios, ele gera artefatos de dados (CSVs e HTML) para responder perguntas de neg√≥cio.

### üìÇ Artefatos Gerados e Explica√ß√£o Detalhada

Ao rodar este script, a pasta `reports/` √© populada com:

#### 1. Relat√≥rio Interativo (`sweetviz_report.html`)

Um dashboard HTML offline gerado pela biblioteca **Sweetviz**.

- **O que mostra:** Compara a distribui√ß√£o de todas as vari√°veis lado a lado (Fraude vs Leg√≠timo).
- **Para que serve:** Permite ver visualmente diferen√ßas de comportamento (ex: "Fraudes tendem a ocorrer mais em contas rec√©m-criadas?"). Mostra correla√ß√µes e valores faltantes de forma interativa.

#### 2. Tabelas de Dados (`reports/data/*.csv`)

Arquivos estruturados para persist√™ncia e an√°lise quantitativa:

- **`data_quality.csv`**:
  - **Conte√∫do:** Tipos de dados, contagem de nulos, percentual de nulos e cardinalidade (valores √∫nicos).
  - **Uso:** Identificar "sujeira" nos dados. Ex: Colunas com 99% de nulos devem ser descartadas.
- **`outliers_iqr.csv`**:
  - **Conte√∫do:** Quantidade e porcentagem de outliers detectados pelo m√©todo IQR (Interquartile Range).
  - **Uso:** Decidir estrat√©gia de tratamento (capping, remo√ß√£o ou uso de modelos robustos a outliers como √Årvores).
- **`statistical_tests_mann_whitney.csv`**:
  - **Conte√∫do:** Resultado do teste de hip√≥tese Mann-Whitney U.
  - **Interpreta√ß√£o:** Se `p-value < 0.05`, a diferen√ßa entre o comportamento de fraudadores e clientes genu√≠nos √© estatisticamente significativa naquela vari√°vel.
  - **Valor:** Valida√ß√£o cient√≠fica de que a feature √© √∫til.
- **`mutual_information_scores.csv`**:
  - **Conte√∫do:** Ranking de import√¢ncia das features calculado via Entropia/Information Gain.
  - **Diferencial:** Captura rela√ß√µes n√£o-lineares que a correla√ß√£o comum ignora. As features no topo dessa lista s√£o os melhores "sinais" de fraude.
- **`descriptive_statistics.csv`**:
  - **Conte√∫do:** M√©dia, desvio padr√£o, m√≠nimo, m√°ximo e quartis.
  - **Uso:** Entender a escala dos dados (ex: valores monet√°rios variam de 10 a 1 milh√£o?).
- **`correlation_matrix.csv`**:
  - **Conte√∫do:** Matriz de correla√ß√£o de Spearman.
  - **Uso:** Detectar multicolinearidade (vari√°veis redundantes que podem confundir modelos lineares).

#### 3. Visualiza√ß√µes Est√°ticas (`reports/figures/eda/*.png`)

- **Comparativo de Boxplots:** Mostra a dispers√£o e outliers separando as classes. Usa escala logar√≠tmica para visualizar valores distorcidos.
- **Matriz de Correla√ß√£o:** Heatmap para identificar visualmente vari√°veis correlacionadas.
- **Risco Categ√≥rico:** Gr√°ficos de barra mostrando a probabilidade de fraude por categoria (ex: Risco por tipo de pagamento).

---

## ü•ä M√≥dulo 2: Compara√ß√£o de Modelos (`compare_models.py`)

Ap√≥s entender os dados, este script realiza um "Torneio" entre algoritmos para decidir qual arquitetura tem melhor performance potencial.

### üß† Metodologia de Avalia√ß√£o

N√£o basta medir Acur√°cia! Em fraude (1% dos dados), um modelo que diz "tudo √© leg√≠timo" tem 99% de acur√°cia, mas √© in√∫til. Por isso, usamos uma estrat√©gia avan√ßada:

1.  **Valida√ß√£o Cruzada Estratificada (Stratified K-Fold)**:
    - Divide os dados em 5 partes, mantendo a propor√ß√£o de fraude em cada parte. Garante que o teste n√£o seja "sorte".
2.  **Pipeline Anti-Leakage (Preven√ß√£o de Vazamento)**:
    - O balanceamento de classes (SMOTE) √© aplicado **dentro** de cada rodada de valida√ß√£o, apenas nos dados de treino. Isso simula o cen√°rio real de produ√ß√£o e evita resultados artificialmente bons.

### üèÜ Competidores (Algoritmos)

- **Logistic Regression**: O baseline simples e explic√°vel.
- **Decision Tree**: Captura regras de decis√£o simples (If-Else).
- **Random Forest**: Cria centenas de √°rvores para reduzir a vari√¢ncia e o risco de overfit.
- **Gradient Boosting (Sklearn)**: Constr√≥i √°rvores sequencialmente, corrigindo o erro da anterior.
- **XGBoost / LightGBM**: O estado da arte em dados tabulares. Otimizados para velocidade e performance extrema.

### üìÇ Artefatos Gerados

#### 1. Relat√≥rio de Ranking (`model_comparison_report.txt`)

Um resumo executivo contendo:

- Tabela com o desempenho m√©dio de cada modelo.
- Desvio padr√£o das m√©tricas (indica se o modelo √© est√°vel ou inst√°vel).
- **Vencedor Geral**: Recomenda√ß√£o autom√°tica baseada no ROC-AUC.

#### 2. Tabela de Resultados (`models_comparison_results.csv`)

Arquivo bruto com todas as m√©tricas calculadas:

- **ROC-AUC**: Capacidade de distin√ß√£o entre classes. Melhor m√©trica geral.
- **Recall (Sensibilidade)**: De 100 fraudes, quantas o modelo pegou? (Cr√≠tico para bancos: perder fraude = preju√≠zo).
- **Precision**: Dos alertas gerados, quantos eram realmente fraude? (Cr√≠tico para opera√ß√£o: muito alerta falso = custo operacional).
- **F1-Score**: M√©dia harm√¥nica entre Precision e Recall.

#### 3. Gr√°fico Comparativo (`model_comparison_metrics.png`)

Um gr√°fico de barras agrupadas que permite ver, lado a lado, como cada modelo se sai em todas as dimens√µes (n√£o apenas uma m√©trica isolada).

---

## üîß M√≥dulo 3: Feature Engineering (`build_features.py`)

Este m√≥dulo √© o "c√©rebro matem√°tico" do projeto. Ele converte os dados brutos em matrizes otimizadas para algoritmos de Machine Learning.

### ‚öôÔ∏è Funcionalidades Chave

- **Detec√ß√£o Autom√°tica de Tipos**: Separa vari√°veis Num√©ricas e Categ√≥ricas automaticamente.
- **Padroniza√ß√£o Robusta (`RobustScaler`)**:
  - Diferente do `StandardScaler` (comum), o `RobustScaler` usa a mediana e o intervalo interquartil (IQR).
  - _Por que?_ Em finan√ßas, uma transa√ß√£o de R$ 1MM n√£o deve "estragar" a escala das transa√ß√µes de R$ 50. Isso torna o modelo imune a valores extremos.
- **Tratamento de Nulos**:
  - Num√©ricos: Preenchidos com a Mediana.
  - Categ√≥ricos: Preenchidos com a tag 'missing'.
- **Pipeline de Infer√™ncia**: Salva apenas o transformador (sem dados) para garantir que novos dados de produ√ß√£o passem exatamente pelo mesmo tratamento do treino.

### üìÇ Artefatos Gerados

- **`models/preprocessor.joblib`**: O objeto serializado contendo todas as regras de transforma√ß√£o (m√©dias, escalas, dicion√°rios one-hot). Essencial para o script de predi√ß√£o.

---

## üß† M√≥dulo 4: Treinamento & Otimiza√ß√£o Multi-Modelo

Nesta etapa, elevamos o n√≠vel do projeto. Ao inv√©s de confiar em apenas um algoritmo, implementamos uma **estrat√©gia de orquestra√ß√£o multi-modelo**. Treinamos e otimizamos rigorosamente quatro arquiteturas distintas, cada uma com seus pontos fortes, para garantir que a solu√ß√£o final seja a mais robusta poss√≠vel.

### üöÄ Estrat√©gia de Treinamento

1. **Pipeline Completo por Modelo**: Cada algoritmo possui seu pr√≥prio script dedicado (`src/models/*_model.py`), contendo um pipeline que encapsula pr√©-processamento, balanceamento (Class Weights/Cost-Sensitive Learning) e o modelo em si.
2. **Preven√ß√£o de Data Leakage**: Garantimos que transforma√ß√µes sejam aplicadas dentro do K-Fold.
3. **Otimiza√ß√£o Bayesiana/Grid (GridSearchCV)**: Exploramos exaustivamente o espa√ßo de hiperpar√¢metros para encontrar a configura√ß√£o ideal.
4. **Threshold Tuning (Ajuste Fino de Decis√£o)**: Ap√≥s o treino, rodamos um algoritmo que encontra o limiar de probabilidade exato que maximiza o F1-Score, abandonando o padr√£o ing√™nuo de 0.5.

### üèÜ Os 4 Pilares (Modelos Implementados)

#### 1. Logistic Regression (`reg_log_model.py`)

O baseline robusto e interpret√°vel. Excelente para estabelecer um "piso" de performance.

- **Por que usar?** Simplicidade, rapidez e coeficientes que explicam diretamente o impacto de cada feature.
- **Hiperpar√¢metros Otimizados:**
  - `C` (Regulariza√ß√£o): Controla a penalidade para erros. Valores menores (`0.01`) evitam overfitting.
  - `Penalty` (`l1` vs `l2`): `l1` (Lasso) pode zerar coeficientes irrelevantes (sele√ß√£o de features autom√°tica), enquanto `l2` (Ridge) apenas reduz seus pesos.
  - `Class Weight`: 'balanced' para penalizar erros na classe minorit√°ria.

#### 2. Decision Tree (`decision_tree_model.py`)

Captura rela√ß√µes n√£o-lineares simples e regras de neg√≥cio expl√≠citas ("Se valor > X e Hora < Y, ent√£o Fraude").

- **Por que usar?** Alta interpretabilidade visual e capacidade de capturar padr√µes que fogem da linearidade.
- **Hiperpar√¢metros Otimizados:**
  - `max_depth`: Limita a profundidade da √°rvore para evitar que ela "decore" o treino (overfitting).
  - `min_samples_split`: O m√≠nimo de exemplos necess√°rios para criar uma nova regra (n√≥). Valores altos deixam o modelo mais conservador.
  - `criterion`: (`gini` vs `entropy`) A m√©trica matem√°tica usada para decidir a melhor "pergunta" a fazer em cada n√≥.

#### 3. Random Forest (`random_forest_model.py`)

O "cl√°ssico" de competi√ß√µes. Cria uma floresta de √°rvores decisionais aleat√≥rias e vota na maioria.

- **Por que usar?** Extremamente robusto a overfitting e ru√≠do. Geralmente performa muito bem "out-of-the-box".
- **Hiperpar√¢metros Otimizados:**
  - `n_estimators`: N√∫mero de √°rvores na floresta (`100`, `200`). Mais √°rvores = mais estabilidade (mas mais lento).
  - `max_depth`: Profundidade m√°xima de cada √°rvore individual (`20` foi o ideal).
  - `class_weight`: Ajuste interno para penalizar mais o erro na classe minorit√°ria (Fraude).

#### 4. XGBoost (`xgboost_model.py`)

O estado da arte (SOTA) em dados tabulares. Utiliza Gradient Boosting, onde cada nova √°rvore corrige os erros da anterior.

- **Por que usar?** Velocidade e precis√£o cir√∫rgica. √â o padr√£o de mercado para sistemas de fraude de alta performance.
- **Hiperpar√¢metros Otimizados:**
  - `learning_rate`: A velocidade com que o modelo aprende.
  - `scale_pos_weight`: Um par√¢metro cr√≠tico para dados desbalanceados. Diz ao modelo para dar `90x` mais aten√ß√£o aos casos de fraude do que aos leg√≠timos.
  - `max_depth`: Profundidade das √°rvores (XGBoost prefere √°rvores mais "rasas" que Random Forest).

### üìÇ Artefatos Gerados

Cada modelo gera seus pr√≥prios artefatos para total rastreabilidade:

- **`models/[MODELO]_best_model.pkl`**: O bin√°rio final pronto para produ√ß√£o.
- **`models/[MODELO]_best_model_params.txt`**: Relat√≥rio de par√¢metros vencedores.
- **`models/[MODELO]_threshold.txt`**: O limiar de decis√£o otimizado.
- **`reports/experiments_log.json`**: Um log unificado com o hist√≥rico de todos os experimentos, m√©tricas e IDs de execu√ß√£o.

---

## üìà M√≥dulo 5: Avalia√ß√£o Final (`visualize.py`)

A "prova real". Este script pega o modelo final e o submete a dados que ele **nunca viu na vida** (`X_test`).

### üìä Gr√°ficos de Valida√ß√£o

#### 1. Matriz de Confus√£o (`confusion_matrix.png`)

- O teste definitivo. Mostra:
  - **Verdadeiros Positivos**: Fraudes que pegamos.
  - **Falsos Negativos**: Fraudes que deixamos passar (Preju√≠zo).
  - **Falsos Positivos**: Clientes honestos que bloqueamos (Atrito).

#### 2. Curva ROC (`roc_curve.png`)

- Mede a qualidade do score de risco. Quanto mais a curva "abra√ßa" o canto superior esquerdo, melhor o modelo sabe separar o trigo do joio.

#### 3. Feature Importance (`feature_importance_coefficients.png`)

- **Explicabilidade (XAI)**. Mostra quais vari√°veis mais pesaram na decis√£o.
  - Ex: "O modelo aprendeu que transa√ß√µes internacionais aumentam o risco?"

---

## üîÆ M√≥dulo 6: Simula√ß√£o de Produ√ß√£o (`predict_model.py`)

Simula uma API Real-Time de antifraude.

### ‚öôÔ∏è Como funciona

1.  Recebe uma "nova transa√ß√£o" (simulada).
2.  Carrega o artefato `preprocessor.joblib` para limpar os dados.
3.  Carrega o modelo `best_model.pkl`.
4.  **Carrega o Threshold Otimizado (`threshold.txt`)**.
5.  **Aplica Decis√£o Inteligente**:
    - Score > Threshold ‚ûî üî¥ **BLOQUEIO AUTOM√ÅTICO**
    - Score > (Threshold \* 0.8) ‚ûî ‚ö†Ô∏è **AN√ÅLISE MANUAL**
    - Score < (Threshold \* 0.8) ‚ûî üü¢ **APROVADO**

---

## üéº O Maestro: Pipeline Completo (`main.py`)

Um orquestrador que roda todo o projeto na ordem correta, garantindo que nada seja esquecido.

### Funcionalidades

- **Limpeza Autom√°tica**: Remove arquivos antigos antes de rodar.
- **Execu√ß√£o Sequencial**: Garante que o Modelo s√≥ treine depois que os Dados existam.
- **Argumentos Flex√≠veis**: Voc√™ pode pular etapas lentas (como EDA ou Compara√ß√£o).

### üöÄ Exemplos de Execu√ß√£o

**1. Rodar TUDO (Do zero √† produ√ß√£o):**

```bash
python main.py
```

**2. Rodar r√°pido (Pular gr√°ficos pesados e compara√ß√£o de modelos):**

```bash
python main.py --skip-eda
```

**3. Apenas simular predi√ß√£o (com o modelo atual):**

```bash
python main.py --no-reset --predict --skip-eda
```

---

**Autor:** [Marco Antonio] - Projeto de Portf√≥lio em Data Science & Machine Learning.
