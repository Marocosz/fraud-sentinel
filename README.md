# Fraud Sentinel - Sistema Avancado de Deteccao de Fraudes Bancarias

# Visao Geral do Projeto

| Item                     | Descricao                                                                                                                                                                                                                                                                                             |
| ------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Nome**                 | Fraud Sentinel                                                                                                                                                                                                                                                                                        |
| **Objetivo Principal**   | Desenvolver um pipeline completo de Machine Learning para detectar fraudes em aberturas de contas bancarias, priorizando a maximizacao do Recall (capturar o maximo de fraudes) com controle de Precision (minimizar falsos alarmes).                                                                 |
| **Problema que Resolve** | Fraudes bancarias na abertura de contas causam prejuizos financeiros massivos. O sistema automatiza a triagem de solicitacoes, classificando-as como legitimas ou fraudulentas com base em padroes historicos de comportamento e atributos sociodemograficos.                                         |
| **Contexto de Uso**      | O sistema opera sobre o dataset Bank Account Fraud (BAF) Suite, publicado no NeurIPS 2022, que simula dados reais de aberturas de conta com rotulagem binaria (0 = legitima, 1 = fraude). A taxa de fraude e extremamente baixa (~1%), exigindo tecnicas especializadas de balanceamento e avaliacao. |
| **Tarefa de Mineracao**  | Classificacao Binaria Supervisionada (O problema e resolvido testando multiplos algoritmos e os unindo em um comite de Ensemble, mas a _"natureza"_ do problema matematico ainda e de Classificacao Binaria).                                                                                         |
| **Metodologia**          | CRISP-DM (Cross-Industry Standard Process for Data Mining)                                                                                                                                                                                                                                            |

---

# Como Executar o Projeto

CRIAR DOCKER

## Preparacao dos Dados

Baixe o dataset BAF Suite do Kaggle e coloque em `data/raw/Base.csv`:

> [!NOTE]
> Link para download da base de dados usada (drive): https://drive.google.com/file/d/1KWKHddAwpZ2HAwsWmL0HWlUXFw8HWf9N/view?usp=sharing
>
> Link para download da base de dados usada (kaggle): https://www.kaggle.com/datasets/sgpjesus/bank-account-fraud-dataset-neurips-2022

## Execucao

```bash
# Pipeline completo (primeira vez)
python main.py

# Sem EDA (mais rapido)
python main.py --skip-eda

# Apenas modelos especificos
python main.py --skip-eda --models xgb,rf

# Com simulacao de producao
python main.py --predict

# Sem limpeza (reuso de dados processados)
python main.py --no-reset --skip-eda --models xgb

# Ajuste fino de Precision
python src/models/force_precision.py 0.20
```

# Sum√°rio

- [Fraud Sentinel - Sistema Avancado de Deteccao de Fraudes Bancarias](#fraud-sentinel---sistema-avancado-de-deteccao-de-fraudes-bancarias)
- [Visao Geral do Projeto](#visao-geral-do-projeto)
- [Como Executar o Projeto](#como-executar-o-projeto)
  - [Preparacao dos Dados](#preparacao-dos-dados)
  - [Execucao](#execucao)
- [Sum√°rio](#sum√°rio)
- [1 Resultados da Analise Exploratoria (EDA)](#1-resultados-da-analise-exploratoria-eda)
  - [1.1 Carga e Qualidade Vis√£o Geral](#11-carga-e-qualidade-vis√£o-geral)
  - [1.2 O Problema do Desbalanceamento](#12-o-problema-do-desbalanceamento)
  - [1.3 Signific√¢ncia Estat√≠stica das Vari√°veis](#13-signific√¢ncia-estat√≠stica-das-vari√°veis)
  - [1.4 Import√¢ncia de Features via Mutual Information (MI)](#14-import√¢ncia-de-features-via-mutual-information-mi)
  - [1.5 An√°lise de Risco Categ√≥rico: Onde mora a Fraude?](#15-an√°lise-de-risco-categ√≥rico-onde-mora-a-fraude)
  - [1.6 O Problema de Outliers: Escala √© Essencial](#16-o-problema-de-outliers-escala-√©-essencial)
  - [1.7 Downcasting de Mem√≥ria Otimizada](#17-downcasting-de-mem√≥ria-otimizada)
- [2. Arquitetura Geral](#2-arquitetura-geral)
  - [2.1 Tipo de Arquitetura](#21-tipo-de-arquitetura)
  - [2.2 Diagrama da Arquitetura](#22-diagrama-da-arquitetura)
  - [2.3 Fluxo Macro (Requisicao ate Resposta)](#23-fluxo-macro-requisicao-ate-resposta)
    - [1. Ingest√£o de Dados](#1-ingest√£o-de-dados)
    - [2. An√°lise Explorat√≥ria (EDA)](#2-an√°lise-explorat√≥ria-eda)
    - [4. Treinamento e Otimiza√ß√£o](#4-treinamento-e-otimiza√ß√£o)
    - [5. Avalia√ß√£o Final](#5-avalia√ß√£o-final)
    - [6. Previs√£o Discreta (Opcional)](#6-previs√£o-discreta-opcional)
  - [2.4 Separacao de Camadas](#24-separacao-de-camadas)
- [3. Estrutura de Diretorios](#3-estrutura-de-diretorios)
  - [3.1 Descricao Detalhada de Cada Arquivo](#31-descricao-detalhada-de-cada-arquivo)
    - [main.py - Orquestrador Principal](#mainpy---orquestrador-principal)
    - [src/data/make\_dataset.py - Engenharia de Dados](#srcdatamake_datasetpy---engenharia-de-dados)
    - [src/features/build\_features.py - Pipeline de Features (EDA-Driven)](#srcfeaturesbuild_featurespy---pipeline-de-features-eda-driven)
    - [src/models/trainers/reg\_log\_model.py - Logistic Regression](#srcmodelstrainersreg_log_modelpy---logistic-regression)
    - [src/models/trainers/decision\_tree\_model.py - Decision Tree](#srcmodelstrainersdecision_tree_modelpy---decision-tree)
    - [src/models/trainers/random\_forest\_model.py - Random Forest](#srcmodelstrainersrandom_forest_modelpy---random-forest)
    - [src/models/trainers/xgboost\_model.py - XGBoost](#srcmodelstrainersxgboost_modelpy---xgboost)
    - [src/models/trainers/mlp\_model.py - MLP Neural Network](#srcmodelstrainersmlp_modelpy---mlp-neural-network)
    - [src/models/trainers/isolation\_forest\_model.py -- Isolation Forest](#srcmodelstrainersisolation_forest_modelpy----isolation-forest)
    - [src/serving/simulate\_production.py -- Simulacao de Producao](#srcservingsimulate_productionpy----simulacao-de-producao)
    - [src/models/force\_precision.py -- Ajuste de Precision-Alvo](#srcmodelsforce_precisionpy----ajuste-de-precision-alvo)
    - [src/visualization/generate\_eda\_report.py -- EDA Automatizada](#srcvisualizationgenerate_eda_reportpy----eda-automatizada)
    - [src/visualization/visualize.py -- Avaliacao Final](#srcvisualizationvisualizepy----avaliacao-final)
- [4. Fluxos Detalhados](#4-fluxos-detalhados)
  - [4.1 Fluxo Principal do Sistema](#41-fluxo-principal-do-sistema)
  - [4.2 Fluxo de Treinamento de Modelo (Generico)](#42-fluxo-de-treinamento-de-modelo-generico)
  - [4.3 Fluxo de Inferencia (Predicao com Ensemble)](#43-fluxo-de-inferencia-predicao-com-ensemble)
  - [4.4 Fluxo de Tratamento de Erros](#44-fluxo-de-tratamento-de-erros)
  - [4.5 Fluxo de Logs](#45-fluxo-de-logs)
- [5. Banco de Dados](#5-banco-de-dados)
- [6. Regras de Negocio](#6-regras-de-negocio)
  - [6.1 Regras de Classificacao](#61-regras-de-classificacao)
  - [6.2 Regras de Balanceamento](#62-regras-de-balanceamento)
  - [6.3 Regras de Validacao](#63-regras-de-validacao)
  - [6.4 Regras de Versionamento de Modelos](#64-regras-de-versionamento-de-modelos)
  - [6.5 Regras de Motor de Decisao](#65-regras-de-motor-de-decisao)
- [7. Logica e Algoritmos](#7-logica-e-algoritmos)
  - [7.1 Otimizacao de Memoria (Downcasting)](#71-otimizacao-de-memoria-downcasting)
  - [7.2 Threshold Tuning](#72-threshold-tuning)
  - [7.3 IForestWrapper (Adapter Pattern)](#73-iforestwrapper-adapter-pattern)
  - [7.4 Amostragem Estratificada para GridSearch](#74-amostragem-estratificada-para-gridsearch)
  - [7.5 Informacao Mutua (MI)](#75-informacao-mutua-mi)
  - [7.6 EDAFeatureEngineer (Feature Engineering Orientado por Dados)](#76-edafeatureengineer-feature-engineering-orientado-por-dados)
  - [7.7 Abstra√ß√£o de Treinamento (`BaseTrainer`)](#77-abstra√ß√£o-de-treinamento-basetrainer)
  - [7.8 Motor de Simula√ß√£o (Ensemble PoV \& ROI)](#78-motor-de-simula√ß√£o-ensemble-pov--roi)
- [8. Configuracoes e Variaveis de Ambiente](#8-configuracoes-e-variaveis-de-ambiente)
- [9. Estrategia de Logs e Monitoramento](#9-estrategia-de-logs-e-monitoramento)
  - [9.1 Logs em Console](#91-logs-em-console)
  - [9.2 Log Persistido (experiments\_log.json)](#92-log-persistido-experiments_logjson)
  - [9.3 Diagnostico de Problemas](#93-diagnostico-de-problemas)
- [10. Teoria Tecnica Envolvida](#10-teoria-tecnica-envolvida)
  - [10.1 Padr√µes de Projeto (Engenharia de Software em MLOps)](#101-padr√µes-de-projeto-engenharia-de-software-em-mlops)
  - [10.2 A Teoria dos Modelos: Por que Foram Selecionados e Como Operam](#102-a-teoria-dos-modelos-por-que-foram-selecionados-e-como-operam)
    - [1. Regress√£o Log√≠stica (Logistic Regression)](#1-regress√£o-log√≠stica-logistic-regression)
    - [2. √Årvores de Decis√£o \& Random Forest (Ensambles de Bagging)](#2-√°rvores-de-decis√£o--random-forest-ensambles-de-bagging)
    - [3. M√°quinas de Vetores de Gradiente (Gradient Boosting - XGBoost e LightGBM)](#3-m√°quinas-de-vetores-de-gradiente-gradient-boosting---xgboost-e-lightgbm)
    - [4. Redes Neurais Profundas (Multilayer Perceptron - MLP)](#4-redes-neurais-profundas-multilayer-perceptron---mlp)
    - [5. Isolation Forest (N√£o-Supervisionado / Geom√©trico)](#5-isolation-forest-n√£o-supervisionado--geom√©trico)
  - [10.3 O Enfrentamento do Desbalanceamento Extremo Sistem√°tico](#103-o-enfrentamento-do-desbalanceamento-extremo-sistem√°tico)
  - [10.4 Threshold Tuning vs Corte Euclidiano Cl√°ssico](#104-threshold-tuning-vs-corte-euclidiano-cl√°ssico)
  - [10.5 O Porqu√™ da Estat√≠stica n√£o-Param√©trica Adotada na EDA](#105-o-porqu√™-da-estat√≠stica-n√£o-param√©trica-adotada-na-eda)
- [11. Melhorias Futuras](#11-melhorias-futuras)
  - [11.1 Melhorias de Performance](#111-melhorias-de-performance)
  - [11.2 Refatoracoes Recomendadas](#112-refatoracoes-recomendadas)
- [12. An√°lise Cr√≠tica e Explica√ß√£o dos Experimentos](#12-an√°lise-cr√≠tica-e-explica√ß√£o-dos-experimentos)
  - [12.1 Os Casos de Fracasso (Exemplos Negativos)](#121-os-casos-de-fracasso-exemplos-negativos)
    - [12.1.1 √Årvore de Decis√£o Simples (`DecisionTreeClassifier`)](#1211-√°rvore-de-decis√£o-simples-decisiontreeclassifier)
    - [12.1.2 Floresta de Isolamento (`IForestWrapper` / Isolation Forest)](#1212-floresta-de-isolamento-iforestwrapper--isolation-forest)
  - [12.2. A Transi√ß√£o e o Progresso](#122-a-transi√ß√£o-e-o-progresso)
    - [12.2.1 Floresta Aleat√≥ria (`RandomForestClassifier`)](#1221-floresta-aleat√≥ria-randomforestclassifier)
    - [12.2.2 Regress√£o Log√≠stica (`LogisticRegression`)](#1222-regress√£o-log√≠stica-logisticregression)
  - [12.3 A Vanguarda Num√©rica (Exemplos Positivos)](#123-a-vanguarda-num√©rica-exemplos-positivos)
    - [12.3.1 Redes Neurais C√≠bridas (`MLPClassifier` - Perceptron Multicamadas)](#1231-redes-neurais-c√≠bridas-mlpclassifier---perceptron-multicamadas)
    - [12.3.2 M√°quinas de Gradient Boosting (`XGBClassifier` \& `LGBMClassifier`)](#1232-m√°quinas-de-gradient-boosting-xgbclassifier--lgbmclassifier)

# 1 Resultados da Analise Exploratoria (EDA)

<details>
<summary>Clique para expandir a An√°lise Explorat√≥ria de Dados (EDA)</summary>

A partir do arquivo `generate_eda_report.py` criamos um relatorio textual (`reports/eda_summary.txt`) com o sumario completo da base de dados. A seguir estao todas as informacoes e descricoes geradas a partir da analise da base inicial.

## 1.1 Carga e Qualidade Vis√£o Geral

O dataset analisado simula aberturas de contas banc√°rias com uma vari√°vel alvo (`fraud_bool`) indicando legitimidade (0) ou fraude (1). O volume de dados √© massivo, o que garante representatividade estat√≠stica.

- **Volume de Dados:** 1.000.000 de registros √∫nicos.
- **Dimensionalidade:** 32 features (9 Num√©ricas Cont√≠nuas, 18 Num√©ricas Discretas, 5 Categ√≥ricas).
- **Qualidade B√°sica:** 0 nulos e 0 duplicados confirmados. A integridade estrutural da base economiza etapas de _imputation_ massivas.

<br>

<details>
<summary><b> Ver Tabela Completa de Cardinalidade e Tipagem</b></summary>

| Coluna                         | Tipo    | Cardinalidade |     | Coluna                      | Tipo    | Cardinalidade |
| ------------------------------ | ------- | ------------- | --- | --------------------------- | ------- | ------------- |
| `fraud_bool`                   | int64   | 2             |     | `credit_risk_score`         | int64   | 551           |
| `income`                       | float64 | 9             |     | `email_is_free`             | int64   | 2             |
| `name_email_similarity`        | float64 | 998.861       |     | `housing_status`            | object  | 7             |
| `prev_address_months_count`    | int64   | 374           |     | `phone_home_valid`          | int64   | 2             |
| `current_address_months_count` | int64   | 423           |     | `phone_mobile_valid`        | int64   | 2             |
| `customer_age`                 | int64   | 9             |     | `bank_months_count`         | int64   | 33            |
| `days_since_request`           | float64 | 989.330       |     | `has_other_cards`           | int64   | 2             |
| `intended_balcon_amount`       | float64 | 994.971       |     | `proposed_credit_limit`     | float64 | 12            |
| `payment_type`                 | object  | 5             |     | `foreign_request`           | int64   | 2             |
| `zip_count_4w`                 | int64   | 6.306         |     | `source`                    | object  | 2             |
| `velocity_6h`                  | float64 | 998.687       |     | `session_length_in_minutes` | float64 | 994.887       |
| `velocity_24h`                 | float64 | 998.940       |     | `device_os`                 | object  | 5             |
| `velocity_4w`                  | float64 | 998.318       |     | `keep_alive_session`        | int64   | 2             |
| `bank_branch_count_8w`         | int64   | 2.326         |     | `device_distinct_emails_8w` | int64   | 4             |
| `date_of_birth_distinct...`    | int64   | 40            |     | `device_fraud_count`        | int64   | 1             |
| `employment_status`            | object  | 7             |     | `month`                     | int64   | 8             |

</details>

## 1.2 O Problema do Desbalanceamento

O principal desafio deste Dataset n√£o √© a qualidade do dado, mas sim a assimetria da vari√°vel alvo:

- **Contas Leg√≠timas:** **98.90%** (988.971)
- **Fraudes:** Apenas **1.10%** (11.029)

**üîπ O que isso significa para o Neg√≥cio?**
Um modelo "burro" que negue todas as aberturas de conta teria 98.90% de "Acur√°cia", mas quebraria a institui√ß√£o banc√°ria ao rejeitar todos os clientes leg√≠timos. A prioridade matem√°tica passa a ser m√©tricas como **Recall** (quantas das fraudes reais n√≥s pegamos?) controlando o **F1-Score / Precision** (quantos clientes bons n√≥s negamos por engano?). Isso nos for√ßa a usar t√©cnicas de _Cost-Sensitive Learning_ na modelagem.

<br>

## 1.3 Signific√¢ncia Estat√≠stica das Vari√°veis

Buscamos entender se o padr√£o de quem comete fraude √© genuinamente diferente do cliente comum. Para vari√°veis cont√≠nuas que raramente seguem Distribui√ß√£o Normal (Gaussiana), n√£o testamos apenas m√©dias, mas toda a "forma" da curva atrav√©s do Teste U de Mann-Whitney.

> \*‚ÑπÔ∏è **Gloss√°rio Explicativo: Teste U de Mann-Whitney\***
> _Um teste estat√≠stico n√£o-param√©trico. Em vez de calcular qual a m√©dia da idade dos fraudadores vs leg√≠timos, ele ranqueia todos os clientes ordenados por idade e avalia se os fraudadores consistentemente ocupam posi√ß√µes mais altas rankeadas de forma sistem√°tica._

**Resultado:** 24 de 26 vari√°veis num√©ricas apresentam padr√µes matem√°ticos significativamente diferentes para o grupo de fraude (p-value < 0.05). As exclus√µes foram `session_length_in_minutes` e `device_fraud_count`.

<details>
<summary><b> Expandir Resultados do Teste de Hip√≥tese (P-Values)</b></summary>

| Variavel                           | Mann-Whitney Stat | P-Value   | Conclusao              |
| ---------------------------------- | ----------------- | --------- | ---------------------- |
| `customer_age`                     | 65.564.824,5      | ~0.00     | Significativo (p<0.05) |
| `credit_risk_score`                | 66.698.262,5      | ~0.00     | Significativo (p<0.05) |
| `prev_address_months_count`        | 39.783.177,5      | 6.23e-300 | Significativo (p<0.05) |
| `proposed_credit_limit`            | 63.877.277,0      | 8.18e-296 | Significativo (p<0.05) |
| `income`                           | 64.323.855,0      | 4.86e-281 | Significativo (p<0.05) |
| `current_address_months_count`     | 63.932.505,5      | 2.91e-255 | Significativo (p<0.05) |
| `keep_alive_session`               | 38.390.000,0      | 3.35e-238 | Significativo (p<0.05) |
| `date_of_birth_distinct_emails_4w` | 37.493.070,0      | 5.98e-207 | Significativo (p<0.05) |
| `has_other_cards`                  | 42.870.000,0      | 1.46e-170 | Significativo (p<0.05) |
| `name_email_similarity`            | 39.904.832,0      | 5.43e-135 | Significativo (p<0.05) |
| `phone_home_valid`                 | 41.975.000,0      | 6.33e-128 | Significativo (p<0.05) |
| `bank_branch_count_8w`             | 41.159.136,0      | 2.41e-105 | Significativo (p<0.05) |
| `email_is_free`                    | 56.960.000,0      | 3.28e-89  | Significativo (p<0.05) |
| `device_distinct_emails_8w`        | 53.088.699,0      | 4.00e-66  | Significativo (p<0.05) |
| `intended_balcon_amount`           | 45.446.320,0      | 6.85e-29  | Significativo (p<0.05) |
| `velocity_6h`                      | 45.459.988,5      | 9.98e-29  | Significativo (p<0.05) |
| `foreign_request`                  | 51.275.000,0      | 1.52e-21  | Significativo (p<0.05) |
| `days_since_request`               | 46.319.316,5      | 1.96e-19  | Significativo (p<0.05) |
| `month`                            | 53.497.183,5      | 5.90e-18  | Significativo (p<0.05) |
| `phone_mobile_valid`               | 47.975.000,0      | 1.85e-17  | Significativo (p<0.05) |
| `velocity_4w`                      | 46.741.244,0      | 1.44e-15  | Significativo (p<0.05) |
| `bank_months_count`                | 46.855.019,5      | 4.28e-15  | Significativo (p<0.05) |
| `velocity_24h`                     | 47.016.792,0      | 2.73e-13  | Significativo (p<0.05) |
| `zip_count_4w`                     | 51.794.874,5      | 1.10e-05  | Significativo (p<0.05) |
| `session_length_in_minutes`        | 50.570.011,0      | 1.63e-01  | Nao Significativo      |
| `device_fraud_count`               | 50.000.000,0      | 1.00      | Nao Significativo      |

</details>

<br>

## 1.4 Import√¢ncia de Features via Mutual Information (MI)

Correla√ß√£o de Pearson (linear) falha miseravelmente em contextos de fraude onde os preditores s√£o cat√©rgicos bin√°rios ou n√£o lineares. O Score de "Informa√ß√£o M√∫tua" (MI) √© matematicamente imune a esses problemas estat√≠sticos.

> \*‚ÑπÔ∏è **Gloss√°rio Explicativo: Mutual Information (MI)\***
> _Mede a redu√ß√£o da nossa "incerteza" estat√≠stica sobre a fraude ao conhecermos uma dada vari√°vel. √â a quantidade de informa√ß√£o (em bits ou nats) que uma vari√°vel compartilha sobre a outra, podendo capturar sinergias ocultas._

**üîπ O que isso significa para o Neg√≥cio?**
As tr√™s vari√°veis de mais alto poder preditivo de fraude n√£o s√£o "idade" ou "renda" do cliente, mas sim sua "Jornada Digital" no momento da abertura da conta. O ranking de MI nos revela um atacante que:

1. Reitera o uso do dispositivo com e-mails massivos diferenciados (`device_distinct_emails`).
2. Utiliza e-mails gratuitos (`email_is_free`) que s√£o muito f√°ceis de serem gerados em lote por rob√¥s.
3. N√£o mant√©m engajamento duradouro com a sess√£o (`keep_alive_session`).

<details>
<summary><b> Expandir Ranking de Mutual Information</b></summary>

| Posicao | Variavel                                                    | MI Score |
| ------- | ----------------------------------------------------------- | -------- |
| 1       | `device_distinct_emails_8w`                                 | 0.010217 |
| 2       | `email_is_free`                                             | 0.010028 |
| 3       | `keep_alive_session`                                        | 0.009970 |
| 4       | `phone_mobile_valid`                                        | 0.007698 |
| 5       | `phone_home_valid`                                          | 0.006016 |
| 6       | `proposed_credit_limit`                                     | 0.004636 |
| 7       | `customer_age`                                              | 0.004512 |
| 8       | `income`                                                    | 0.003630 |
| 9       | `has_other_cards`                                           | 0.001935 |
| 10      | `credit_risk_score`                                         | 0.001892 |
| ...     | demais contidas na matriz integral do arquivo `eda_summary` | ...      |

</details>

<br>

## 1.5 An√°lise de Risco Categ√≥rico: Onde mora a Fraude?

Os modelos de regress√£o de √°rvore de decis√£o ir√£o iterar sobre fatias dos dados (Splits de n√≥s). A an√°lise das frequ√™ncias revelam de antem√£o por onde as parti√ß√µes iniciar√£o o corte das vari√°veis de alto impacto na triagem:

- **Sistema Operacional do Fraudadador (`device_os`):** Acessos atrav√©s de navegadores Desktop Windows possu√≠ram taxa de Fraude base de **2.47%** (mais do que o dobro do padr√£o global da base).
- **Emprego (`employment_status`):** Usu√°rios classificados pela flag opaca "CC" tem incid√™ncia de **2.47%**.
- **Moradia (`housing_status`):** Aten√ß√£o cr√≠tica √† tag de moradia "BA". Ela puxa estonteantes **3.75%** de volume de fraude na sub-amostra; Este √© um nicho quase 3.4x mais t√≥xico estatisticamente do que um usu√°rio n√£o pertencente a esta classe.

**üîπ O que isso significa para o Neg√≥cio?**
Um solicitante via _Teleapp_ (Aplicativo Telefonico - Fraude Base = 1.59%), que utilize Windows (Fraude= 2.47%) e seja da base Habitacional Categoria _BA_ (Fraude=3.75%) deve ser sumariamente bloqueado ou submetido √† triagem manual pesada de preven√ß√£o antes da emiss√£o de cart√µes tempor√°rios.

<br>

## 1.6 O Problema de Outliers: Escala √© Essencial

Em modelos n√£o baseados em ramifica√ß√£o em √Årvores (ex. Regress√£o Log√≠stica e Redes Neurais - Multilayer Perceptron), outliers extremos causam explos√µes nos vetores de otimiza√ß√£o de gradiente.

> \*‚ÑπÔ∏è **Gloss√°rio Explicativo: M√©todo IQR (Interquartile Range)\***
> _Ao inv√©s de definir que um valor √© an√¥malo s√≥ porque ele √© maior que a m√©dia + Desvio Padr√£o, o m√©todo inter-quartil ordena todo o dataset, observa estritamente os usu√°rios do "meio" (do percentil 25 ao 75) tra√ßando uma fronteira em seu tamanho, punindo dados fora dessa redoma da "normalidade"._

Aferimos o dataset usando o limite "Boxplot" padr√£o de 1.5x o IQR.

**üîπ O que isso significa para o Neg√≥cio?**
Vari√°veis como `proposed_credit_limit` tem um surto: **24.17%** da base √© qualificada estatisticamente como Outlier. A Feature `bank_branch_count_8w` passa disso, chegando a distor√ß√µes grav√≠ssimas em 17% dos clientes. Estes limites astron√¥micos far√£o as Redes Neurais perderem o rumo (Backpropagation instability). Teremos obrigatoriamente que aplicar `MinMaxScaler` ou `RobustScaler` com percentuais _clipados (Clipping)_ rigorosos no desenvolvimento das pipelines de engenharia de dados.

<details>
<summary><b> Tabela Completa de Outliers por Features </b></summary>

| Variavel                       | Outliers | % Outliers | Limite Inferior | Limite Superior |
| ------------------------------ | -------- | ---------- | --------------- | --------------- |
| `proposed_credit_limit`        | 241.742  | 24.17%     | -250.00         | 950.00          |
| `has_other_cards`              | 222.988  | 22.30%     | 0.00            | 0.00            |
| `intended_balcon_amount`       | 222.702  | 22.27%     | -10.43          | 14.23           |
| `bank_branch_count_8w`         | 175.243  | 17.52%     | -35.00          | 61.00           |
| `prev_address_months_count`    | 157.320  | 15.73%     | -20.50          | 31.50           |
| `phone_mobile_valid`           | 110.324  | 11.03%     | 1.00            | 1.00            |
| `days_since_request`           | 94.834   | 9.48%      | -0.02           | 0.06            |
| `session_length_in_minutes`    | 78.789   | 7.88%      | -5.54           | 17.51           |
| `zip_count_4w`                 | 59.871   | 5.99%      | -681.00         | 3519.00         |
| `current_address_months_count` | 41.001   | 4.10%      | -147.50         | 296.50          |
| `device_distinct_emails_8w`    | 31.933   | 3.19%      | 1.00            | 1.00            |
| `foreign_request`              | 25.242   | 2.52%      | 0.00            | 0.00            |

</details>

<br>

## 1.7 Downcasting de Mem√≥ria Otimizada

O uso de mem√≥ria de 240MB pode n√£o parecer grande na base bruta, mas quando um pipeline efetua One-Hot Encoding ou SMOTE (Aumento de dimensionalidade gerando fatiamento de arrays no C++ / Cython), geramos sobrecarga no kernel ou at√© mesmo _Memory Leaks_.

> \*‚ÑπÔ∏è **Gloss√°rio Explicativo: Memory Downcasting\***
> _Consiste em ler e analisar as var√°veis est√°ticas nas mem√≥rias e perceber se suas propriedades se apoiam perfeitamente num espa√ßo alocado imensamente menor da arquitetura padr√£o._

A maior parte dos booleanos do projeto n√£o requer vetores do tipo `int64` alocados, e sim `int8`.
O _Footprint_ da base de dados ser√° drasticamente reduzido pelos scripts em Python para que o tuning e simula√ß√µes com os modelos de √Årvore Random Forest ocorram lisos e otimizados pelo hardware durante a Pipeline.

</details>

---

# 2. Arquitetura Geral

## 2.1 Tipo de Arquitetura

O Fraud Sentinel adota uma **arquitetura modular orientada a pipeline**, organizada em camadas funcionais independentes. Cada camada possui responsabilidade unica e se comunica com as demais exclusivamente atraves de artefatos persistidos em disco (arquivos CSV, PKL, JSON e TXT). Essa abordagem garante reprodutibilidade, rastreabilidade e desacoplamento entre etapas.

## 2.2 Diagrama da Arquitetura

```
+------------------------------------------------------------------+
|                        main.py (MAESTRO)                         |
|            Orquestrador Central / CLI com argparse               |
+------------------------------------------------------------------+
         |              |              |              |
         v              v              v              v
+----------------+ +----------+ +-------------+
| make_dataset   | | EDA      | | train_*     |
| (Data Eng.)    | | Reporter | | _model.py   |
+----------------+ +----------+ +-------------+
    |                  |              |
    v                  v              v
+--------+      +-----------+  +------------+
| data/  |      | reports/  |  | models/    |
|processed|     | figures/  |  | *.pkl      |
| *.csv  |      | *.png     |  | *.txt      |
+--------+      +-----------+  +------------+
                                                    |
                                    +---------------+--------+
                                    v                        v
                             +------------+          +-------------+
                             | visualize  |          | predict     |
                             | .py        |          | _model.py   |
                             | (Avaliacao)|          | (Inferencia)|
                             +------------+          +-------------+
```

## 2.3 Fluxo Macro (Requisicao ate Resposta)

### 1. Ingest√£o de Dados

- **Arquivo Respons√°vel:** `make_dataset.py`
- **Entrada:** `data/raw/Base.csv` (Dataset BAF Suite - NeurIPS 2022)
  - √â a base bruta contendo features comportamentais de aberturas de conta e o r√≥tulo de fraude (`fraud_bool`). O pipeline todo depende dessa massa de dados para o treinamento.
- **Descri√ß√£o da Atividade:**
  1. Carrega o CSV bruto.
  2. Aplica _downcasting_ de tipos num√©ricos (ex: `float64` para `float32`) visando reduzir intensamente o consumo de RAM.
  3. Valida se a coluna target existe.
  4. Separa os dados de Forma Estratificada (80/20) para preservar o percentual de fraude (aprox. 1%).
- **Sa√≠da Gerada:** Quatro artefatos isolados para o framework scikit-learn (`data/processed/X_train.csv`, `X_test.csv`, `y_train.csv`, `y_test.csv`).

### 2. An√°lise Explorat√≥ria (EDA)

- **Arquivo Respons√°vel:** `generate_eda_report.py`
- **Entrada:** `data/raw/Base.csv` (Original, sem aplicar limpezas intermedi√°rias).
- **Descri√ß√£o da Atividade:**
  1. Cria um check-up dos dados calculando estat√≠sticas descritivas b√°sicas.
  2. Otimiza quantifica√ß√£o de Outliers pela regra do IQR.
  3. Aciona o c√°lculo estat√≠stico de Mann-Whitney U e o agrupamento condicional `Mutual Information` rankeando a capacidade de previs√£o de cada vari√°vel.
  4. Monta as correla√ß√µes visuais e cria o HTML Sweetviz.
- **Sa√≠da Gerada:** Tabelas de suporte em `reports/data/*.csv`, Gr√°ficos PNG das varia√ß√µes (em `reports/figures/eda/`), Relat√≥rio textual `reports/eda_summary.txt` e o painel din√¢mico `reports/sweetviz_report.html`.

### 4. Treinamento e Otimiza√ß√£o

- **Arquivos Respons√°veis:** `reg_log_model.py`, `decision_tree_model.py`, `random_forest_model.py`, `xgboost_model.py`, `mlp_model.py`, `isolation_forest_model.py`
- **Entrada:** `data/processed/X_train.csv`, `y_train.csv`.
- **Descri√ß√£o da Atividade:**
  1. Para cada modelo acionado, cria a `Pipeline` (junta o Transformador/Escalonador com o Classificador).
  2. Executa a _GridSearchCV_ procurando o melhor pacote de Hiperpar√¢metros.
  3. Consolida ensinando ao modelo a base inteira num retreino _Champion_.
  4. Varre a Curva _Precision-Recall_ para calibrar um threshold (limiar de decis√£o) otimizado.
- **Sa√≠da Gerada:** Os c√©rebros treinados `models/*_best_model.pkl` prontos para infer√™ncia em disco r√≠gido, seus versionamentos para hist√≥rico, os textos dos limiares de decis√£o `*_threshold.txt`, as configs √≥timas `*_best_model_params.txt`, e a persist√™ncia total dos scores operacionais via `reports/experiments_log.json`.

### 5. Avalia√ß√£o Final

- **Arquivo Respons√°vel:** `visualize.py`
- **Entrada:** `data/processed/X_test.csv`, `y_test.csv` (Os dados intocados de blind-test). Puxa tamb√©m os `.pkl` gerados no passo anterior.
- **Descri√ß√£o da Atividade:**
  A etapa exp√µe o modelo ao Teste Cego para extrair suas probabilidades e classe predita. Processa as m√©tricas definitivas (ROC-AUC, Precision, Recall, F1) e consolida os gr√°ficos avaliativos.
- **Sa√≠da Gerada:** Gr√°ficos cruciais da capacidade em tempo real (`reports/figures/confusion_matrix_*.png`, etc) e uma atualiza√ß√£o direta da linha final constando as m√©tricas no log unificado `experiments_log.json`.

### 6. Previs√£o Discreta (Opcional)

- **Arquivo Respons√°vel:** `predict_model.py` (Orquestrado por `main.py` com a flag `--predict`)
- **Entrada:** Pipeline Final Serializado `models/*_best_model.pkl` do algoritmo validado.
- **Descri√ß√£o da Atividade:**
  1. Carrega amostras do Dataset de Teste.
  2. Simula o ambiente real e faz predi√ß√µes contendo a probabilidade para as contas n√£o serem leg√≠timas em tempo real.
- **Sa√≠da Gerada:** Exibi√ß√£o em modo console interativa para acompanhamento individual (Aprovado, Bloqueado, etc) do pipeline execut√≥rio.

## 2.4 Separacao de Camadas

| Camada                 | Diretorio            | Responsabilidade                                                                  |
| ---------------------- | -------------------- | --------------------------------------------------------------------------------- |
| Configuracao           | `src/config.py`      | Caminhos, constantes globais, seed aleatoria                                      |
| Engenharia de Dados    | `src/data/`          | Carga, otimizacao de memoria, split estratificado                                 |
| Engenharia de Features | `src/features/`      | Preprocessamento (Scaler, Imputer, OneHot), SMOTE                                 |
| Modelos                | `src/models/`        | Treinamento, otimizacao de hiperparametros, threshold tuning, predicao, benchmark |
| Visualizacao           | `src/visualization/` | EDA automatizada, avaliacao final, graficos                                       |
| Orquestracao           | `main.py`            | Pipeline end-to-end via CLI                                                       |
| Testes                 | `tests/`             | Stubs de testes unitarios (nao implementados)                                     |

---

# 3. Estrutura de Diretorios

```
fraud-sentinel/
|-- main.py                    # Orquestrador principal (CLI)
|-- requirements.txt           # Dependencias do projeto
|-- ideia_inicial.md           # Documento de concepcao e historico de experimentos
|-- .gitignore                 # Regras de exclusao do Git
|-- .env                       # Variaveis de ambiente (vazio)
|
|-- src/                       # Codigo-fonte principal
|   |-- __init__.py            # Torna src um pacote Python
|   |-- config.py              # Configuracoes globais centralizadas
|   |
|   |-- data/
|   |   |-- __init__.py
|   |   |-- make_dataset.py    # Carga, otimizacao e split de dados
|   |
|   |-- features/
|   |   |-- __init__.py
|   |   |-- build_features.py  # Pipeline EDA-driven (EDAFeatureEngineer + Scaler + OneHot)
|   |
|   |-- models/
|   |   |-- __init__.py

|   |   |-- force_precision.py     # Ajuste fino de threshold por Precision-alvo
|   |   |-- threshold_utils.py     # Utilitarios anti-leakage para Thresholds
|   |   |-- trainers/              # Submodulo de Algoritmos Otimizados
|   |       |-- base_trainer.py        # Classe Abstrata (Orquestracao IO e Otimizacao)
|   |       |-- reg_log_model.py       # Treinamento Logistic Regression
|   |       |-- decision_tree_model.py # Treinamento Decision Tree
|   |       |-- random_forest_model.py # Treinamento Random Forest
|   |       |-- xgboost_model.py       # Treinamento XGBoost
|   |       |-- mlp_model.py           # Treinamento MLP (Rede Neural)
|   |       |-- isolation_forest_model.py # Treinamento Isolation Forest
|   |       |-- lightgbm_model.py      # Treinamento LightGBM (Campeao de Precisao)
|   |       |-- stacking_model.py      # Treinamento de Stacking Ensemble
|   |
|   |-- serving/
|   |   |-- __init__.py
|   |   |-- predict_ensemble.py    # Motor de Inferencia MLOps (Comite de Votos)
|   |   |-- simulate_production.py # Simulador CLI de Producao (Streaming Console)
|   |   |-- predict_model.py       # Predicao single-model legado
|
|-- reports/
|   |-- data/                  # CSVs de metricas (qualidade, correlacao, MI, etc.)
|   |-- figures/               # Graficos PNG (EDA, avaliacao, comparacao)
|   |-- eda_summary.txt        # Relatorio textual consolidado da EDA
|   |-- model_comparison_report.txt # Relatorio do benchmark
|   |-- experiments_log.json   # Historico unificado de todos os experimentos
|   |-- sweetviz_report.html   # Dashboard interativo HTML
|   |-- simulation_summary.txt # Relatorio executivo financeiro (ROI) do Ensemble
|
|-- tests/                     # Suite de testes unitarios funcionais (Data e Features)
|   |-- test_data.py           # Testes automatizados do build features
|   |-- test_features.py       # Testes da preparacao otimizada
|
|-- venvmine/                  # Ambiente virtual Python (nao versionado)
```

## 3.1 Descricao Detalhada de Cada Arquivo

### main.py - Orquestrador Principal

| Atributo         | Descricao                                                           |
| ---------------- | ------------------------------------------------------------------- |
| **Funcao**       | Orquestra todo o pipeline na ordem correta via CLI (argparse)       |
| **Funcoes**      | `reset_project_artifacts()`, `main()`                               |
| **Entradas**     | Argumentos CLI: `--no-reset`, `--skip-eda`, `--predict`, `--models` |
| **Saidas**       | Execucao sequencial de todos os modulos                             |
| **Dependencias** | Todos os modulos em `src/`                                          |

Flags disponiveis:

| Flag         | Efeito                              |
| ------------ | ----------------------------------- |
| `--no-reset` | Pula a limpeza de artefatos antigos |
| `--skip-eda` | Pula a analise exploratoria         |

| `--predict` | Roda simulacao de inferencia ao final |
| `--models` | Seleciona modelos especificos (ex: `--models xgb,rf`) |

Identificadores de modelos: `logreg`, `dt`, `rf`, `xgb`, `mlp`, `if`.

### src/data/make_dataset.py - Engenharia de Dados

| Atributo     | Descricao                                                                                   |
| ------------ | ------------------------------------------------------------------------------------------- |
| **Funcoes**  | `optimize_memory_usage(df)`, `load_and_split_data()`                                        |
| **Entrada**  | `data/raw/Base.csv`                                                                         |
| **Saida**    | `data/processed/{X_train, X_test, y_train, y_test}.csv`                                     |
| **Excecoes** | `FileNotFoundError` se Base.csv nao existir; `ValueError` se coluna alvo nao for encontrada |

Fluxo interno:

1. Carrega CSV bruto com `pd.read_csv`
2. Valida existencia da coluna target (fallback para `is_fraud`)
3. Aplica downcasting de tipos (`float64`->`float32`, `int64`->`int8`) para otimizar RAM
4. Separa features (X) e target (y)
5. Executa `train_test_split` com `stratify=y` para manter proporcao de fraude
6. Salva 4 CSVs processados

### src/features/build_features.py - Pipeline de Features (EDA-Driven)

| Atributo    | Descricao                                                                                |
| ----------- | ---------------------------------------------------------------------------------------- |
| **Classe**  | `EDAFeatureEngineer(BaseEstimator, TransformerMixin)` -- Transformer sklearn customizado |
| **Funcoes** | `get_preprocessor(X)`, `build_pipeline(X_train, model)`, `process_features()`            |
| **Entrada** | DataFrame X com features brutas                                                          |
| **Saida**   | `Pipeline` completo de 3 etapas (EDAFeatureEngineer -> ColumnTransformer -> Modelo)      |

O pipeline foi reestruturado com base nos insights da Analise Exploratoria (EDA) e agora possui 3 camadas:

**Camada 1 - EDAFeatureEngineer** (transformer customizado):

| Transformacao            | Detalhe                                                                                                                             | Justificativa (EDA)                                                                       |
| ------------------------ | ----------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- |
| Remocao de features      | Remove `device_fraud_count` e `session_length_in_minutes`                                                                           | Variancia zero (MI=0.0001) e MI=0 com Mann-Whitney nao significativo (p=0.163)            |
| Tratamento de sentinelas | Converte -1 para NaN e cria flags (`has_prev_address`, `has_bank_history`, `has_device_emails`)                                     | Mediana de `prev_address_months_count` = -1 indicava >50% de dados marcados como ausentes |
| Clipping de outliers     | Clip nos percentis 1%/99% de `proposed_credit_limit`, `intended_balcon_amount`, `bank_branch_count_8w`, `prev_address_months_count` | Features com 15-24% de outliers pelo metodo IQR                                           |
| Flags de risco           | Cria `is_high_risk_housing`, `is_high_risk_employment`, `is_high_risk_os`, `is_high_risk_payment`, `is_teleapp_source`              | Categorias com 1.5x a 3.4x a taxa media de fraude                                         |
| Interacao digital        | Cria `digital_risk_score` = `email_is_free` \* `device_distinct_emails_8w`                                                          | Top 3 features por MI Score sao todas de comportamento digital                            |

**Camada 2 - ColumnTransformer** (preprocessamento):

- Pipeline numerico: `SimpleImputer(median)` -> `RobustScaler()`
- Pipeline categorico: `SimpleImputer(constant='missing')` -> `OneHotEncoder(handle_unknown='ignore')`

**Camada 3 - Modelo** (classificador):

- O classificador especifico de cada modelo (LogReg, XGBoost, RF, etc.)

Decisao tecnica: O `EDAFeatureEngineer` e um `BaseEstimator` do scikit-learn, sendo serializado junto com o modelo via `joblib.dump()`. Isso garante que as mesmas transformacoes sejam aplicadas automaticamente em treino, validacao cruzada e inferencia.

### src/models/trainers/reg_log_model.py - Logistic Regression

| Atributo                           | Descricao                                                                                        |
| ---------------------------------- | ------------------------------------------------------------------------------------------------ |
| **Funcao principal**               | `train_logistic_regression()`                                                                    |
| **Estrategia de desbalanceamento** | `class_weight='balanced'` (sem SMOTE)                                                            |
| **Grid Search**                    | `C`: [0.01, 0.1, 1, 10]; `penalty`: ['l1', 'l2']                                                 |
| **Otimizacao**                     | Amostra estratificada de 100k linhas para GridSearch; retreino final com dataset completo        |
| **Saidas**                         | `logreg_best_model.pkl`, `logreg_threshold.txt`, `best_model_params.txt`, `experiments_log.json` |

### src/models/trainers/decision_tree_model.py - Decision Tree

| Atributo             | Descricao                                                                                 |
| -------------------- | ----------------------------------------------------------------------------------------- |
| **Funcao principal** | `train_decision_tree()`                                                                   |
| **Grid Search**      | `max_depth`: [5, 10, None]; `min_samples_split`: [2, 5]; `criterion`: ['gini', 'entropy'] |
| **Saidas**           | `dt_best_model.pkl`, `dt_threshold.txt`, `dt_best_model_params.txt`                       |

### src/models/trainers/random_forest_model.py - Random Forest

| Atributo             | Descricao                                                                            |
| -------------------- | ------------------------------------------------------------------------------------ |
| **Funcao principal** | `train_random_forest()`                                                              |
| **Grid Search**      | `n_estimators`: [100, 200]; `max_depth`: [10, 20, None]; `min_samples_split`: [2, 5] |
| **Nota**             | RF usa `n_jobs=-1` internamente; GridSearch usa `n_jobs=1` para evitar conflito      |
| **Saidas**           | `rf_best_model.pkl`, `rf_threshold.txt`, `rf_best_model_params.txt`                  |

### src/models/trainers/xgboost_model.py - XGBoost

| Atributo             | Descricao                                                                     |
| -------------------- | ----------------------------------------------------------------------------- |
| **Funcao principal** | `train_xgboost()`                                                             |
| **Estrategia**       | `scale_pos_weight=90` para compensar desbalanceamento                         |
| **Grid Search**      | `learning_rate`: [0.01, 0.1]; `n_estimators`: [100, 200]; `max_depth`: [3, 6] |
| **Otimizacao**       | Amostra estratificada de 100k para GridSearch; retreino no dataset completo   |
| **Saidas**           | `xgb_best_model.pkl`, `xgb_threshold.txt`, `xgb_best_model_params.txt`        |

### src/models/trainers/mlp_model.py - MLP Neural Network

| Atributo             | Descricao                                                                                                                                          |
| -------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Funcao principal** | `train_mlp()`                                                                                                                                      |
| **Grid Search**      | `hidden_layer_sizes`: [(50,), (100,), (50,25)]; `activation`: ['relu','tanh']; `alpha`: [0.0001, 0.001, 0.01]; `learning_rate_init`: [0.001, 0.01] |
| **Nota**             | Usa `early_stopping=True` com 10% de validacao interna                                                                                             |
| **Saidas**           | `mlp_best_model.pkl`, `mlp_threshold.txt`                                                                                                          |

### src/models/trainers/isolation_forest_model.py -- Isolation Forest

| Atributo             | Descricao                                                                                                       |
| -------------------- | --------------------------------------------------------------------------------------------------------------- |
| **Funcao principal** | `train_isolation_forest()`                                                                                      |
| **Classe auxiliar**  | `IForestWrapper(BaseEstimator, ClassifierMixin)` -- Wrapper que converte `decision_function` em `predict_proba` |
| **Nota**             | Algoritmo nao-supervisionado adaptado para pipeline supervisionado. Sem GridSearch.                             |
| **Parametros fixos** | `n_estimators=200`, `contamination=0.01`                                                                        |
| **Saidas**           | `if_best_model.pkl`, `if_threshold.txt`                                                                         |

A classe `IForestWrapper` inverte o score de anomalia (`-decision_function`), normaliza com `MinMaxScaler` para [0,1] e empacota no formato `predict_proba` padrao `(n_samples, 2)`.

### src/serving/simulate_production.py -- Simulacao de Producao

| Atributo                     | Descricao                                                                                    |
| ---------------------------- | -------------------------------------------------------------------------------------------- |
| **Funcoes**                  | `load_inference_artifacts()`, `load_threshold()`, `explain_prediction()`, `predict_sample()` |
| **Motor de decisao**         | Score > Threshold -> BLOQUEIO; Score > Threshold\*0.8 -> REVISAO MANUAL; Abaixo -> APROVADO  |
| **Estrategia de amostragem** | Forca 50% de fraude na demonstracao para visualizacao                                        |

### src/models/force_precision.py -- Ajuste de Precision-Alvo

| Atributo             | Descricao                                                               |
| -------------------- | ----------------------------------------------------------------------- |
| **Funcao principal** | `enforce_precision_target(target_precision, model_filename)`            |
| **Objetivo**         | Encontrar o menor threshold que garanta Precision >= alvo (padrao: 20%) |
| **Metodologia**      | Varredura da curva Precision-Recall no conjunto de teste                |
| **Saidas**           | Sobrescreve `*_threshold.txt`, gera `precision_optimization_curve.png`  |

### src/visualization/generate_eda_report.py -- EDA Automatizada

| Atributo              | Descricao                                                                                                                                                                                                                                                                                                                                                                                    |
| --------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Classe**            | `EDAReporter`                                                                                                                                                                                                                                                                                                                                                                                |
| **Metodos**           | `load_data`, `generate_structure_report`, `analyze_categorical_domain`, `analyze_outliers`, `generate_statistics_report`, `perform_statistical_tests`, `calculate_mutual_information`, `plot_comparative_boxplots`, `plot_temporal_analysis`, `plot_target_distribution`, `plot_correlations`, `plot_all_histograms`, `plot_categorical_risks`, `generate_interactive_report`, `save_report` |
| **Artefatos gerados** | `data_quality.csv`, `outliers_iqr.csv`, `statistical_tests_mann_whitney.csv`, `mutual_information_scores.csv`, `descriptive_statistics.csv`, `correlation_matrix.csv`, `sweetviz_report.html`, `eda_summary.txt`, 7+ graficos PNG                                                                                                                                                            |

### src/visualization/visualize.py -- Avaliacao Final

| Atributo         | Descricao                                                               |
| ---------------- | ----------------------------------------------------------------------- |
| **Funcoes**      | `plot_coefficients(model, feature_names)`, `evaluate(model_name)`       |
| **Graficos**     | Matriz de Confusao, Curva ROC, Feature Importance (coeficientes)        |
| **Persistencia** | Atualiza `experiments_log.json` com metricas de avaliacao no blind test |

---

# 4. Fluxos Detalhados

## 4.1 Fluxo Principal do Sistema

```
[Usuario] --> python main.py
    |
    v
[reset_project_artifacts]
    Limpa data/processed/*.csv (exceto .gitkeep)
    |
    v
[load_and_split_data]
    Le data/raw/Base.csv
    Otimiza tipos (float64->float32, int64->int8)
    Valida coluna target (fraud_bool ou is_fraud)
    Split 80/20 estratificado
    Salva X_train.csv, X_test.csv, y_train.csv, y_test.csv
    |
    v
[EDAReporter.run] (se --skip-eda NAO ativo)
    Le data/raw/Base.csv
    Gera metricas de qualidade, testes estatisticos, graficos
    Salva em reports/
    |
    v
[Para cada modelo selecionado (--models)]:
    [train_*()]
        Le X_train.csv, y_train.csv
        Cria preprocessor via get_preprocessor()
        Monta Pipeline: preprocessor -> modelo
        GridSearchCV com StratifiedKFold (3 folds)
        Retreina no dataset completo com melhores params
        Threshold Tuning (maximiza F1 na curva PR)
        Salva modelo.pkl, threshold.txt, params.txt
        Registra em experiments_log.json
    [evaluate()]
        Le X_test.csv, y_test.csv
        Le modelo.pkl
        Gera predicoes e probabilidades
        Calcula metricas (AUC, F1, Precision, Recall)
        Gera Matriz de Confusao, Curva ROC
        Atualiza experiments_log.json
    |
    v
[simulate_production] (se --predict ativo)
    Inicia Comite Ensemble (predict_ensemble.py)
    Le os modelos XGB, MLP, LGBM e seus thresholds
    Sorteia batch de transacoes do X_test (embaralhado)
    Aplica motor Voting com Veto Financeiro
    Imprime feed visual da previsao no console
    Computa e Salva simulation_summary.txt (Relatorio em $)
```

## 4.2 Fluxo de Treinamento de Modelo (Generico)

```
train_*():
    [BaseTrainer - Classe Abstrata Orquestradora]
    1. run_id = timestamp atual
    2. _load_data(): Carrega X_train e y_train do PKL e ravel().
    3. pipeline = build_pipeline(X_train, clf)
    4. _get_sample(): Amostragem rigorosa (`stratify=y`) para Busca R√°pida de Hiperpar√¢metros.
    5. compute_sample_weight(): Aplica balanceamento de Pesos Cost-Sensitive para suprir Desbalanceamento.
    6. GridSearchCV / RandomizedSearchCV configurado conforme `config.py` injetado pelo modelo.
    7. Retreina melhor estimador em Dataset Completo.
    8. threshold_utils.compute_optimal_threshold() -> argmax(F1).
    9. joblib.dump do Modelo Campe√£o e Versionado `model_*_{run_id}.pkl`.
   10. Appenda log de m√©tricas da valida√ß√£o cruzada no `experiments_log.json`.
```

## 4.3 Fluxo de Inferencia (Predicao com Ensemble)

```
simulate_production() -> predict_ensemble() :
    1. predictor = FraudEnsemblePredictor() carrega modelos .pkl e threshold.txt (ex: LightGBM, XGBoost, MLP)
    2. X_test, y_test s√£o carregados e embaralhados.
    3. Para cada transacao fornecida em streaming:
       a. Calcula proba para os 3 modelos e computa contra os seus 3 thresholds otimizados.
       b. Majority Vote Logic (Smart Ensemble c/ Veto Especial):
          - Se Fraud_Votes >= Majority_Threshold (ex: 2/3): BLOQUEIO (Alta Confian√ßa)
          - Se Fraud_Votes > 0 E Votante Unico == 'LightGBM': REVIS√ÉO MANUAL (Veto de Precis√£o)
          - Senao: APROVADO (Nivel de Risco Assumido)
    4. Atualiza os TPs, FPs, TNs e FNs em Real Time.
    5. Imprime resultado consolidado visual Terminal CLI.
    6. Quando finalizado, computa ROI e Atrito -> reports/simulation_summary.txt
```

## 4.4 Fluxo de Tratamento de Erros

Os erros sao tratados em 3 niveis:

1. **Importacao**: Bloco try/except global em `main.py` que aborta com `sys.exit(1)` se modulos estiverem faltando
2. **Dados**: `FileNotFoundError` se CSVs nao existirem; `ValueError` se coluna target nao for encontrada
3. **Modelos**: Fallback de threshold para 0.5 se `*_threshold.txt` nao existir

## 4.5 Fluxo de Logs

O sistema utiliza `logging.basicConfig` com saida para `stdout`. Cada modelo gera logs com formato padrao `%(asctime)s - %(levelname)s - %(message)s`. Alem disso, o `experiments_log.json` funciona como log persistido de todos os experimentos.

---

# 5. Banco de Dados

O Fraud Sentinel **nao utiliza banco de dados relacional ou NoSQL**. A persistencia e inteiramente baseada em arquivos:

| Tipo              | Formato             | Localizacao                    | Finalidade                      |
| ----------------- | ------------------- | ------------------------------ | ------------------------------- |
| Dados brutos      | CSV                 | `data/raw/Base.csv`            | Dataset BAF Suite original      |
| Dados processados | CSV                 | `data/processed/`              | Splits de treino/teste          |
| Modelos           | PKL (Pickle/Joblib) | `models/`                      | Modelos serializados            |
| Thresholds        | TXT                 | `models/`                      | Limiares de decisao otimizados  |
| Parametros        | TXT                 | `models/`                      | Hiperparametros vencedores      |
| Historico         | JSON                | `reports/experiments_log.json` | Log unificado de experimentos   |
| Metricas EDA      | CSV                 | `reports/data/`                | Tabelas de analise exploratoria |
| Visualizacoes     | PNG                 | `reports/figures/`             | Graficos de avaliacao           |
| Dashboard         | HTML                | `reports/sweetviz_report.html` | EDA interativa                  |

A estrategia de "banco de dados" e baseada em **flat files**, onde cada execucao appenda ao `experiments_log.json` e versiona modelos com timestamps no nome (`model_xgb_20260218_105559.pkl`).

---

# 6. Regras de Negocio

## 6.1 Regras de Classificacao

- O target e binario: `fraud_bool` = 0 (legitima) ou 1 (fraude)
- O threshold de decisao NAO e 0.5 fixo. E otimizado por modelo via maximizacao do F1-Score na curva Precision-Recall
- A decisao final e trinivelada: BLOQUEIO automatico, REVISAO manual, ou APROVACAO

## 6.2 Regras de Balanceamento

- SMOTE foi testado nos experimentos 1 e 2, mas **removido** no experimento final por gerar "Dupla Penalizacao" (excesso de falsos positivos)
- A estrategia vencedora usa **Cost-Sensitive Learning**: `class_weight='balanced'` (LogReg, RF, DT) ou `scale_pos_weight=90` (XGBoost)

## 6.3 Regras de Validacao

- Split estratificado obrigatorio (`stratify=y`) para manter proporcao de fraude
- Preprocessamento ocorre **dentro** do pipeline para evitar Data Leakage
- Algoritmos dependem de balanceador sem√¢ntico estat√≠stico e pesos (`class_weight`, `scale_pos_weight`) aplicados a n√≠vel de CV Fold.
- GridSearch avalia por `roc_auc` (metrica independente de threshold)

## 6.4 Regras de Versionamento de Modelos

- Modelo "latest" em `{nome}_best_model.pkl` (sempre sobrescrito)
- Modelo historico em `model_{nome}_{timestamp}.pkl` (nunca sobrescrito)
- Pasta de modelos nao e limpa pelo reset para manter historico

## 6.5 Regras de Motor de Decisao

```
Se (Votos de Fraude do Comit√™) >= Maioria (2+ de 3): --> BLOQUEIO AUTOMATICO (Alto Risco)
Se (Votos = 1) E (Voto de Fraude originado pelo LightGBM): --> REVISAO MANUAL (M√©dio/Alto Risco - Veto de Campe√£o)
Outros Casos (Voto 0 ou voto √∫nico de modelo fraco):  --> APROVADO (Baixo Risco Aceit√°vel)
```

---

# 7. Logica e Algoritmos

## 7.1 Otimizacao de Memoria (Downcasting)

O algoritmo em `optimize_memory_usage()` itera por todas as colunas e verifica se o range de valores cabe em tipos menores (`int8`, `int16`, `float32`), reduzindo significativamente o footprint de memoria para datasets com milhoes de linhas.

## 7.2 Threshold Tuning

Todos os modelos executam apos o treinamento:

1. Calculam `predict_proba` no conjunto de treino
2. Geram a curva Precision-Recall com todos os thresholds possiveis
3. Calculam F1 = 2*(P*R)/(P+R) para cada threshold
4. Selecionam o threshold que maximiza F1

Isso substitui o corte ingenuo de 0.5 por um ponto de operacao otimizado para o problema.

## 7.3 IForestWrapper (Adapter Pattern)

O Isolation Forest nao implementa `predict_proba` nativamente. O `IForestWrapper` aplica o padrao Adapter:

1. `fit()`: Treina o IF e ajusta um `MinMaxScaler` nos scores de decisao invertidos
2. `predict()`: Converte -1 (anomalia) para 1 (fraude) e 1 (normal) para 0
3. `predict_proba()`: Normaliza scores para [0,1] e retorna formato `(n, 2)`

## 7.4 Amostragem Estratificada para GridSearch

LogReg e XGBoost usam amostra de 100k linhas para GridSearch (economia de horas de processamento), seguida de retreino no dataset completo com os parametros vencedores.

## 7.5 Informacao Mutua (MI)

A EDA calcula Mutual Information com `mutual_info_classif` para ranquear features por capacidade preditiva, capturando relacoes nao-lineares que correlacao de Pearson/Spearman ignora.

## 7.6 EDAFeatureEngineer (Feature Engineering Orientado por Dados)

O `EDAFeatureEngineer` e um transformer customizado do scikit-learn que aplica 5 transformacoes baseadas nos insights da EDA, em sequencia:

```
Dados Brutos (31 features)
    |
    v
1. Remocao: -2 features (device_fraud_count, session_length_in_minutes)
    |
    v
2. Sentinelas: -1 -> NaN + 3 flags binarias (has_prev_address, has_bank_history, has_device_emails)
    |
    v
3. Clipping: Percentis 1%/99% em 4 features com >15% outliers
    |
    v
4. Flags de Risco: +5 features binarias (housing BA, employment CC, OS windows, payment AC, source TELEAPP)
    |
    v
5. Interacao Digital: +1 feature (digital_risk_score = email_is_free * device_distinct_emails_8w)
    |
    v
Dados Engenheirados (38 features)
```

O transformer implementa `fit()` para aprender limites de clipping no conjunto de treino e `transform()` para aplicar todas as transformacoes. Por ser um `BaseEstimator`, e automaticamente serializado junto com o modelo.

## 7.7 Abstra√ß√£o de Treinamento (`BaseTrainer`)

Refatora o problema de duplica√ß√£o que existia na vers√£o prim√°ria, gerando Orienta√ß√£o a Objetos. A classe orquestra subamostragem `_get_sample()` rigorosa estratificada, inje√ß√£o de depend√™ncias de modelos arbitr√°ria, resolve uni√£o entre `GridSearchCV` e `RandomizedSearchCV`, define pesos usando `compute_sample_weight` e automatiza a trilha de Logs (`experiments_log.json`).

## 7.8 Motor de Simula√ß√£o (Ensemble PoV & ROI)

Implementado com vetores `pandas` de alt√≠ssima velocidade, prev√™ dados em "Batch Array" diretamente pelos 3 Modelos Comit√™ otimizados simultaneamente (MLP, Xgb, LightGBM). Utiliza CLI (Command Line Interface) Visual para reportar:

- O Veredito de Maioria Simples ou Veto Especial, traduzidos em True Positives e False Negatives.
- Uma Intelig√™ncia de Neg√≥cio Financeira (`simulate_production.py`) cruza os erros contra um Ticket M√©dio de neg√≥cio predefinido e entrega ao usu√°rio e Stakeholders um Documento final (`simulation_summary.txt`) contendo Patrim√¥nio Salvo, Custo de Atrito, Taxa da Opera√ß√£o e o Lucro Resgatado em Dinheiro Requerido.

---

# 8. Configuracoes e Variaveis de Ambiente

| Variavel       | Arquivo             | Finalidade                     | Valor        |
| -------------- | ------------------- | ------------------------------ | ------------ |
| `RANDOM_STATE` | `config.py`         | Semente para reprodutibilidade | 42           |
| `TEST_SIZE`    | `config.py`         | Proporcao do split de teste    | 0.2          |
| `TARGET_COL`   | `config.py`         | Coluna alvo                    | `fraud_bool` |
| `SAMPLE_SIZE`  | Modelos individuais | Amostra para GridSearch        | 100000       |
| `CV_FOLDS`     | Modelos individuais | Folds de validacao cruzada     | 3            |
| `.env`         | Raiz                | Reservado (vazio)              | --           |

---

# 9. Estrategia de Logs e Monitoramento

## 9.1 Logs em Console

Todos os modulos utilizam `logging.basicConfig` com nivel `INFO` e saida para `stdout`. O formato padrao e `%(asctime)s - %(levelname)s - %(message)s`.

## 9.2 Log Persistido (experiments_log.json)

Cada treinamento appenda um registro contendo:

- `run_id` (timestamp)
- `model_type`, `smote_strategy`, `best_params`
- `best_cv_score`, `best_threshold`
- `model_path` (nome do arquivo versionado)
- Metricas de avaliacao (AUC, classification_report, confusion_matrix) -- adicionadas pelo `visualize.py`

## 9.3 Diagnostico de Problemas

1. **Modelo nao encontrado**: Verificar se `main.py` foi executado antes de `simulate_production.py`
2. **Memoria insuficiente**: Reduzir `SAMPLE_SIZE` nos modelos ou usar `--models` para treinar menos modelos
3. **Threshold nao encontrado**: O sistema faz fallback para 0.5 com warning

---

# 10. Teoria Tecnica Envolvida

Esta se√ß√£o √© dedicada a aprofundar academicamente e cientificamente as decis√µes arquiteturais, matem√°ticas e de modelagem tomadas durante a constru√ß√£o do **Fraud Sentinel**. A engenharia de um pipeline de detec√ß√£o de fraudes em _onboarding_ (Application Fraud) requer muito mais do que empilhar bibliotecas de c√≥digo; exige uma defesa te√≥rica s√≥lida para lidar com o ru√≠do massivo e a raridade impl√≠cita do ataque.

## 10.1 Padr√µes de Projeto (Engenharia de Software em MLOps)

A base de c√≥digo transcende _scripts_ soltos, abra√ßando **Object-Oriented Programming (OOP)** e padr√µes consolidados da Engenharia de Software cl√°ssica aplicados ao Aprendizado de M√°quina:

| Padr√£o Aplicado             | Como e Por Que Foi Utilizado                                                                                                                                                                                                                                                                                                                                                                          |
| :-------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Facade (Fachada)**        | O orquestrador `BaseTrainer` simplifica brutalmente a subamostragem, a inje√ß√£o de depend√™ncias e a aplica√ß√£o de _Cost-Sensitive Learning_ por debaixo dos panos. O usu√°rio final s√≥ interage com uma fachada simples (`train_xgboost()`), enquanto o subsistema complexo resolve a otimiza√ß√£o de matriz e as salvaguardas de IO.                                                                      |
| **Adapter (Adaptador)**     | Utilizado ativamente no `IForestWrapper`. O algoritmo n√£o-supervisionado _Isolation Forest_ do _scikit-learn_ n√£o retorna probabilidades (n√£o possui a interface `predict_proba`). O adaptador contorna essa lacuna, capturando o `decision_function`, invertendo seus sinais e o espremendo via `MinMaxScaler(0,1)`, compatibilizando a anomalia cega com o resto da arquitetura estrita do sistema. |
| **Pipeline (Encadeamento)** | Imuniza√ß√£o arquitetural contra o **Data Leakage** (vazamento de dados estat√≠sticos do futuro para o fold de treino). A constru√ß√£o usa `sklearn.pipeline.Pipeline`, embutindo limpezas complexas (IQR Clipping) dentro do Cross-Validation, garantindo que nenhum modelo veja as m√©tricas da base de teste.                                                                                            |
| **Strategy (Estrat√©gia)**   | Cada classe no diret√≥rio `trainers/` obedece a um contrato comum: inicializa um dicion√°rio de Grid, encapsula sua classe nativa (ex: `XGBClassifier`) e lan√ßa na rotina mestra.                                                                                                                                                                                                                       |

---

## 10.2 A Teoria dos Modelos: Por que Foram Selecionados e Como Operam

O _Fraud Sentinel_ n√£o aposta "todas as fichas" em um c√°lculo s√≥. Treinamos um ecossistema variado de algoritmos, apostando que as fraquezas geom√©tricas de um modelo sejam compensadas pela capacidade matem√°tica de outro.

### 1. Regress√£o Log√≠stica (Logistic Regression)

- **A Matem√°tica:** Um modelo param√©trico linear que calcula o log-odds (logaritmo das chances) da combina√ß√£o das features e as espreme em uma curva sigmoide entre probabilidade 0 e 1.
- **Papel no Projeto:** Atua como a **Linha de Base Segura (Baseline)**. Por ser rigorosamente convexa e linear, se uma vari√°vel isolada (ex: `income`) possui forte sinal mon√≥tono de fraude, a LogReg detectar√° de forma est√°vel. No entanto, ela falha miseravelmente em intera√ß√µes n√£o-lineares (ex: quando `idade > 30` E `OS == 'Windows'` indicam fraude, mas isoladamente n√£o sinalizam nada).

### 2. √Årvores de Decis√£o & Random Forest (Ensambles de Bagging)

- **A Matem√°tica:** √Årvores cortam o espa√ßo matem√°tico das features em blocos retangulares (splits) maximizando a "Pureza" (Gini Impurity) e os Ganhos de Informa√ß√£o. A _Random Forest_ gera centenas de √Årvores profundas de forma aleatorizada e amarra suas previs√µes via vota√ß√£o (_Bagging_), destruindo a alt√≠ssima vari√¢ncia caracter√≠stica de uma √∫nica √°rvore isolada.
- **Papel no Projeto:** Robustez bruta e identifica√ß√£o de n√£o-linearidades. O Random Forest raramente sofre _overfitting_ crasso e mapeia nichos ("bolhas" espec√≠ficas de usu√°rios do sistema). Seu principal rev√©s neste contexto √© o alto peso (Modelos pesados, consumindo centenas de MBs) e a dificuldade org√¢nica em lidar com fatias min√∫sculas (1%) de fraude, j√° que as amostragens aleat√≥rias com frequ√™ncia geram √°rvores "cegas" onde nenhuma fraude existiu no subset.

### 3. M√°quinas de Vetores de Gradiente (Gradient Boosting - XGBoost e LightGBM)

- **A Matem√°tica:** Ao inv√©s de criar √°rvores em paralelo como na floresta aleat√≥ria, o _Boosting_ constr√≥i as √°rvores estritamente em s√©rie. A √Årvore B √© otimizada sob o res√≠duo cont√≠nuo (o "erro de gradiente") originado pela √Årvore A.
- **Papel no Projeto:** Constituem o **cora√ß√£o preditivo de precis√£o**. O **LightGBM** √© um campe√£o de particionamento veloz (processamento via histogramas ‚Äì Otimiza√ß√£o por GOSS - Gradient-based One-Side Sampling), focando sua CPU de forma implac√°vel exatamente onde ele mais errou anteriormente (_Hard Examples_). O **XGBoost** compensa com penaliza√ß√µes el√°sticas (L1/L2 estritos nos pesos da folha) e atua perfeitamente capturando o limiar de fraude invis√≠vel aos algoritmos lineares. S√£o eles a for√ßa motriz do "Veto Especial de Fraude" na Arquitetura do Comit√™ de Ensemble.

### 4. Redes Neurais Profundas (Multilayer Perceptron - MLP)

- **A Matem√°tica:** Inspirado fisiologicamente por neur√¥nios abstratos. Aplica centenas de pesos e vieses atrav√©s de opera√ß√µes matriciais consecutivas, retropropagando (Backpropagation) os erros nas derivadas parciais.
- **Papel no Projeto:** Serve para capturar Padr√µes Topol√≥gicos de Alt√≠ssima Dimens√£o. Como nosso dataset √© tabular e possui categorias densas, uma Rede Neural simples apanha consideravelmente do Gradient Boosting (O fen√¥meno da n√£o-localidade dos dados categ√≥ricos contra a for√ßa bruta do aprendizado por parti√ß√£o das √°rvores). Contudo, a MLP no Comit√™ traz ganhos de **Sensibilidade (Recall)** gen√©rica, j√° que suas conex√µes cont√≠nuas costumam n√£o sofrer do vi√©s agudo de bordos r√≠gidos da decis√£o que assombra a √Årvore de Decis√£o convencional.

### 5. Isolation Forest (N√£o-Supervisionado / Geom√©trico)

- **A Matem√°tica:** A anomalia √© "mais f√°cil de isolar" na floresta. Quantos n√≥s (splits matem√°ticos) precisaram ser feitos at√© isolar aquele usu√°rio em uma √∫nica folha? Se ele for "Normal", ele cair√° no meio do emaranhado junto da maioria (demorando v√°rios splits). Se ele for An√¥malo, em apenas dois cortes da √°rvore aleat√≥ria ele ficar√° isolado no espa√ßo vazio do vetor.
- **Papel no Projeto:** Usado para provar que a Fraude de Identidade Sint√©tica (Onboarding) n√£o √© apenas um outlier geom√©trico matem√°tico. Criminosos profissionais tentam mimetizar ao m√°ximo o comportamento natural de uma conta corrente para despistar modelos de IA, caindo na m√©dia. Portanto, rodar "An√°lise de Outliers" isoladamente √© insuficiente contra fraudes modernas.

---

## 10.3 O Enfrentamento do Desbalanceamento Extremo Sistem√°tico

Lidamos com uma preval√™ncia hostil de apenas `1.10%` da classe Fraude (Classe 1). Em problemas preditivos, IAs sempre otimizam pregui√ßosamente convergindo para chutar a Classe Majorit√°ria (aprovando todo mundo) alcan√ßando ~99% de Falsa Acur√°cia.
Enfrentamos de duas formas cruzadas:

1. **A Queda das Resampling (Decad√™ncia do SMOTE)**
   O projeto experimentou criar fraude falsa via _SMOTE (Synthetic Minority Over-sampling Technique)_. A matem√°tica por tr√°s espalha dados artificiais utilizando KNN vizinhos ao redor das fraudes. Contudo, percebemos por testes pr√°ticos de laborat√≥rio o efeito **F√°brica de Fantasmas**: O SMOTE gerava "fraudes redondas e ideais", causando _Over-Confidence_ artificial nas √Årvores de Classifica√ß√£o ao validarem em dados de produ√ß√£o, produzindo falsos alarmes generalizados nos clientes bons. Desligamos a t√©cnica.
2. **Implementa√ß√£o de Cost-Sensitive Learning (Pesos Heur√≠sticos)**
   Ativamos o m√©todo anal√≠tico: Nenhuma linha tabular √© artificialmente adicionada ou exclu√≠da. Em contrapartida, ensinamos para a M√°quina uma matriz punitiva de dor. Na fun√ß√£o perda _(Loss Function/LogLoss)_ do nosso XGBoost, o erro em classificar um cidad√£o bom como Fraude causa √† derivada penalidade padr√£o `1.0`. Todavia, classificar o Fraudador como Cliente Bom inflige penalidade severa multiplicada (`scale_pos_weight = ~90`). Esse arranjo inclina brutalmente as for√ßas da Descida de Gradiente (Gradient Descent), for√ßando a IA estritamente √† cautela rigorosa buscando o menor sinal poss√≠vel da classe escassa para evitar sua penaliza√ß√£o astron√¥mica.

---

## 10.4 Threshold Tuning vs Corte Euclidiano Cl√°ssico

O Default cl√°ssico da intelig√™ncia de c√≥digo aberto dita o limiar est√°tico: A IA afirma que h√° fraude se _P(Fraude) > 0.5 (50%)_.
A teoria de ML Operations deste nosso sistema renega isso agressivamente: Diferentes IAs com fun√ß√µes de custo escaladas absurdamente (como a de ~90 do passo anterior) costumam distorcer brutalmente suas sa√≠das probabil√≠sticas num√©ricas puras (_Proba Calibration_ distorcido e natural das _Decision Trees_).

**Arquitetura de Limiar Computado:** Realizamos a rotina for√ßada buscando do √≠ndice _`0.001`_ ao `0.999`. Compilamos internamente uma malha calculando os Falsos Positivos e Verdadeiros Positivos de forma simult√¢nea. Selecionamos dinamicamente (no pacote `threshold_utils.py`) a casa decimal (Geralmente orbitando entre as probabilidades baix√≠ssimas de `0.06` √† `0.15` e n√£o os ideais _0.5_) que representa o pico extremo da montanha do **Score F1** ‚Äî harmonicamente mediando o limite exato onde a precis√£o de prender bandidos decai menos face √† captura total pretendida do Recall. Este n√∫mero decimal √© extra√≠do e arquivado est√°tico no `.txt` em disco l√≥gico a ser consumido compulsoriamente na simula√ß√£o online pela interface do Sistema do Banco.

---

## 10.5 O Porqu√™ da Estat√≠stica n√£o-Param√©trica Adotada na EDA

Nenhuma feature importante (Ex: Idades ou Velocidade do Onboarding 24h) obedeceu ao Sino de Gauss Puro (Teste padr√£o de Normalidade / Skewness). Dessa forma, a valida√ß√£o n√£o podia ser b√°sica:

1. **Mann-Whitney U Test ao longo do T-Test Cl√°ssico das Universidades:** Para garantir que a diferen√ßa das m√©tricas comportamentais entre Clientes Normais e Fraudadores era puramente ver√≠dica (n√£o um falso acaso), optamos pelo Teste `U` embasado no _Ranking Ordenado de Posi√ß√£o dos √çndices_ e n√£o por "Compara√ß√µes Falsas de M√©dias Cartesianas", validando se as amostras pertencem √† mesma estirpe populacional biol√≥gica ou se divergem fortemente pelo espectro P-Value inferirior a `0.05`.
2. **Mutual Information (MI) como Norteador Superior de Pearson/Spearman:** Correla√ß√µes famosas lineares (A matriz `Pearson`) s√≥ enxergam retas unindo X a Y. Muitas de nossas descobertas operavam por "Ganho de Entropia" (Clusters disjuntos sem l√≥gica aparente linear, mas categorizados em fra√ß√µes de nichos perigosos de forma quadr√°tica ‚Äì A exatid√£o da detec√ß√£o explodindo quando o cruzamento de e-mails ocorria sob um determinado n√∫mero de Telefones). O c√°lculo do MI estipulando sua f√≥rmula embasada em _Redu√ß√£o da Incerteza_ _(Entropy H(x))_ do target validado pelo ganho condicional embasou com blindagem acad√™mica todas as decis√µes da classe matem√°tica org√¢nica embutida e serializada em nosso passo estrito da Pipeline (`EDAFeatureEngineer`).

---

# 11. Melhorias Futuras

## 11.1 Melhorias de Performance

1. **Substituir GridSearchCV por Optuna/BayesSearchCV** para busca ainda mais robusta de hiperparametros em hipercubos densos.
2. **Implementar cache de preprocessamento avan√ßado** para evitar recomputacao entre diferentes parti√ß√µes no motor de CV do `BaseTrainer`.
3. **Usar Parquet em vez de Pickle** caso ocorra imprecis√£o massiva e gargalo nas escritas do disco por datasets multibilion√°rios.

## 11.2 Refatoracoes Recomendadas

1. **Extrair logica de persistencia de experimentos** para um container online (`MLflow` tracking).
2. **Centralizar configuracao de modelos** em um unico YAML/JSON para integra√ß√£o direta a pipelines de Deploy CI/CD em Nuvem (Airflow, KubeFlow).
3. **Implementar Explainable AI (SHAP/LIME)** diretamente conectada na resposta do Comit√™ de Decis√£o (`predict_ensemble.py`) informando qual feature barrou ou aprovou o risco.

---

# 12. An√°lise Cr√≠tica e Explica√ß√£o dos Experimentos

O arquivo `reports/experiments_log.json` consolida os resultados quantitativos de cada ciclo de modelagem. Embora o n√∫mero da Acur√°cia de quase todos os testes seja de 98% a 99%, essa m√©trica √© uma ilus√£o derivada da assimetria extrema do dataset (apenas 1.1% de sub-representa√ß√£o). Em sistemas de fraude impera a necessidade de balizar o trade-off entre bloquear fraudadores e aprovar clientes bons.

Para compreender os resultados, √© imperativo o dom√≠nio dos seguintes conceitos macro-avaliativos:

| M√©trica | Significado no Contexto de Fraude | Impacto de Neg√≥cio |
| :--- | :--- | :--- |
| **Recall** *(Sensibilidade)* | Mede a propor√ß√£o de fraudes reais que o sistema conseguiu detectar. Um Recall de 80% significa que de cada 100 fraudes, pegamos 80 e deixamos passar 20. | Maximizar o Recall √© o **objetivo de seguran√ßa** da institui√ß√£o financeira. |
| **Precision** *(Precis√£o)* | Avalia a propor√ß√£o de acertos quando o sistema "apita" uma fraude. Uma Precis√£o de 20% significa que a cada 100 usu√°rios bloqueados, apenas 20 eram de fato fraudadores. | Minimiza o atrito gerado aos 80 clientes leg√≠timos bloqueados por engano (Falsos Positivos). |
| **F1-Score** | M√©dia harm√¥nica entre Precision e Recall. Pune modelos que tem disparidade extrema entre as duas m√©tricas (ex: Recall 99% mas Precision 1%). | √â a m√©trica de "ponto ideal" para encontrar o melhor **Threshold** (limiar de decis√£o). |
| **PR-AUC** *(Precision-Recall Area)* | Mede a performance geral do modelo atrav√©s de todos os limiares de decis√£o poss√≠veis. | M√©trica mais robusta e segura (muito melhor que a curva ROC tradicional) para datasets desbalanceados. |

Abaixo, detalhamos conceitualmente, tecnicamente e os motivos do sucesso ou fracasso de cada modelo submetido ao laborat√≥rio de modelagem.

---

## 12.1 Os Casos de Fracasso (Exemplos Negativos)

### 12.1.1 √Årvore de Decis√£o Simples (`DecisionTreeClassifier`)

> **üî¥ Resultado Pr√°tico:** Fracasso Cr√≠tico. Apesar de boa m√©trica de treino inicial na valida√ß√£o cruzada (`CV Score = 0.81`), ruiu na base oficial de verifica√ß√£o com `F1-score` colapsando para `0.0`, errando a m√£o completamente no limiar `0.92`.

* **Por que ocorreu? (A Teoria):** Modelos mon√≥tonos foliares baseados em cortes diretos limitados (Gini/Entropy) n√£o suportam desbalanceamento em massa org√¢nico se n√£o receberem *Pruning* (poda) severo muito bem delineado. A √Årvore tenta minimizar a impureza total do n√≥, e na estat√≠stica macro deste conjunto, √© mais f√°cil/barato e matematicamente recompensador para a folha apenas aglutinar massas de volume gigante "Leg√≠timas", declarando `0`, para maximizar estabilidade, engolindo os parcos e irregulares `1` (fraudes) na multid√£o como varrimento de ru√≠do org√¢nico.

**Par√¢metros T√©cnicos Implementados:**

| Par√¢metro | Valor | Conceito e Impacto |
| :--- | :--- | :--- |
| `max_depth` <br>*(Profundidade M√°xima)* | `5` | Define o limite de quantos "n√≠veis" a √°rvore pode descer fazendo subdivis√µes. Usou-se limita√ß√£o de teto deliberada visando atenuar a memoriza√ß√£o viciosa de longo encadeamento (*Overfitting*). O efeito colateral reverso ocorreu subadestrando generaliza√ß√£o no patamar final das parti√ß√µes (o modelo ficou "raso" demais para pegar as nuances da fraude). |

### 12.1.2 Floresta de Isolamento (`IForestWrapper` / Isolation Forest)

> **üî¥ Resultado Pr√°tico:** Incompatibilidade arquitetural na ess√™ncia do ataque. Obteve-se `PR_AUC` p√≠fio de `0.025` e `F1-score` baixo na borda otimizada (`0.061`).

* **Por que ocorreu? (A Teoria):** *Isolation forest* prov√™ isolamento heur√≠stico baseado estritamente na dist√¢ncia topol√≥gica (Quantos "cortes/splits" distam para espremer e exilar o n√≥ an√¥malo longe da densidade padr√£o dimensional). O problema t√©cnico-financeiro atual reside na ess√™ncia da fraude de Identidade Sint√©tica (Onboarding Fraud): Os advers√°rios n√£o s√£o exilados mal-feitos, eles se mimetizam pesadamente para imitarem o ser humano padr√£o limpo do ecossistema e cruzarem o bloqueador da ag√™ncia.
* **Conclus√£o Operacional:** Este n√£o-supervisionado falha rotundamente contra comportamentos que mimetizam ou tentam absorver a m√©dia estat√≠stica. A fraude que nos assola n√£o reflete Anomalia Espacial Pura Outlier.

**Par√¢metros T√©cnicos Implementados:**

| Par√¢metro | Valor | Conceito e Impacto |
| :--- | :--- | :--- |
| `n_estimators` <br>*(N√∫mero de √Årvores)* | `200` | A quantidade de √°rvores isoladas criadas no vetor (usado para estabilizar o consenso). |
| `contamination` <br>*(Contamina√ß√£o)* | `0.01` | Define a estimativa predefinida do n√∫mero de outliers na base de dados (1%). Orienta o algoritmo a separar precocemente o quantitativo da massa isolada que se refere a nossa propor√ß√£o de fraude conhecida. |

---

## 12.2. A Transi√ß√£o e o Progresso

### 12.2.1 Floresta Aleat√≥ria (`RandomForestClassifier`)

> **üü° Resultado Pr√°tico:** Avan√ßo met√≥dico superando os blocos cegos mon√≥tonos do modelo de √°rvore de decis√£o (`F1 = 0.189`, `PR_AUC = 0.115`).

* **Por que ocorreu a melhora? (A Teoria):** Resolve o colapso unit√°rio pela premissa pesada do *Bagging* (Bootstrap Aggregation + Feature Subsampling). Cada uma das sub-√°rvores injetadas absorve pacotes org√¢nicos paralelos misturados randomicamente do conjunto total e reage a amostras microsc√≥picas de colunas pr√©-sorteadas, gerando decorrela√ß√£o for√ßada. O consenso demogr√°fico maci√ßo do modelo oblitera a variabilidade errante e prov√™ generaliza√ß√£o muito est√°vel.
* **Ponto Fraco Met√≥dico:** Random Forests n√£o possuem aprendizado corretivo de repasse matricial temporal. Eles votam por consenso populacional inerte perante os `"Hard Examples"` (casos extremamente dif√≠ceis que comp√µem o fraudador escasso avan√ßado). Eles batem um teto de cristal da complexidade preditiva se estagnando.

**Par√¢metros T√©cnicos Implementados:**

| Par√¢metro | Valor | Conceito e Impacto |
| :--- | :--- | :--- |
| `n_estimators` <br>*(N¬∫ de Estimadores)* | `200` | Quantas √°rvores avulsas comp√µem a floresta. Mais √°rvores garantem estabilidade de consenso populacional, mas aumentam pesadamente o tempo de processamento. |
| `max_features` <br>*(Features Sorteadas)* | `sqrt` | Determina o n√∫mero de vari√°veis que o algoritmo visualizar√° em um √∫nico n√≥ divis√≥rio (raiz quadrada). Cada √°rvore fica "cega" √† vasta maioria das caracter√≠sticas, prevenindo que features fort√≠ssimas dominem todas as √°rvores e trazendo diversidade real. |

### 12.2.2 Regress√£o Log√≠stica (`LogisticRegression`)

> **üü° Resultado Pr√°tico:** Performance assombrosa perante o preconceito t√©cnico do meio. Superou o limite org√¢nico do Random Forest de forma limpa (`F1 = 0.212`, `PR_AUC = 0.137`).

* **Por que funcionou e surpreendeu? (A Teoria):** Executou o *Baseline Benchmark* provando que nossa modelagem de Data Engineering (`Mutual Information` para colunas baseadas no risco org√¢nico interativo do neg√≥cio) possui for√ßa colossal. O algoritmo tra√ßa linearmente hiperplanos nas 38 dimens√µes, apoiando-se unicamente nas rea√ß√µes combinadas.

**Par√¢metros T√©cnicos Implementados:**

| Par√¢metro | Valor | Conceito e Impacto |
| :--- | :--- | :--- |
| `C` <br>*(Regulariza√ß√£o Inversa)* | `0.01` | Controla qu√£o r√≠gido o modelo ser√° contra erros na base. Um valor baixo (0.01) √© intensamente restritivo. Ele obriga o modelo a achar hiperplanos fracos, generalistas, mitigando *overfitting*. Evita que o modelo se adeque a ru√≠dos desnecess√°rios. |
| `penalty` <br>*(Estrat√©gia Punitiva)* | `'l2'` | Ridge Penalty. Impede que as multiplica√ß√µes dos hiperpar√¢metros (como dar pontua√ß√£o muito alta √† idade do cliente) explodam, mantendo os pesos das caracter√≠sticas encolhidos suavemente pr√≥ximos a zero. |

---

## 12.3 A Vanguarda Num√©rica (Exemplos Positivos)

### 12.3.1 Redes Neurais C√≠bridas (`MLPClassifier` - Perceptron Multicamadas)

> **üü¢ Resultado Pr√°tico:** Captura de padr√µes ultra densos. Apresentou alt√≠ssima recupera√ß√£o de captura sens√≠vel para o Pipeline Ensemble (`F1 = 0.220`).

* **Como atua e o por que (A Teoria):** Redes Neurais (Adeptos n√£o-lineares puristas) absorvem correla√ß√µes espaciais ocultas e sequenciamento invis√≠vel relacional. Requerem volumes tit√¢nicos de dados para extrair esses padr√µes sutis.

**Par√¢metros T√©cnicos Implementados:**

| Par√¢metro | Valor | Conceito e Impacto |
| :--- | :--- | :--- |
| `hidden_layer_sizes` <br>*(Topologia Oculta)* | `[128]` | Quantas conex√µes formam os neur√¥nios "abstratos". Adotou-se o padr√£o "Skinny but Wide", processando largura densa de uma vez sem descer n√≠veis paralelos infind√°veis, mantendo f√¥lego em um vetor tabular. |
| `alpha` <br>*(Taxa Punitiva L2)* | `0.001` | An√°logo √† penalidade da LogReg, estabelece teto reacional contra pesos folgados de *Overfitting* latente, limitando a for√ßa bruta excessiva do Backpropagation. |
| `activation` <br>*(Fun√ß√£o de Ativa√ß√£o)* | `'tanh'` | Acionamento de n√£o-linearidade sigmoidal suavizada da Tangente Hiperb√≥lica. Evitou estouros reativos que a ReLU normal causa num sistema estritamente tabular, gerando balan√ßo harm√¥nico em negativo/positivo do gradiente reverso. |
| `learning_rate_init` <br>*(Passo de Converg√™ncia)*| `0.0005` | Definida de forma minimalista est√°tica para decair a "descida da montanha do custo matem√°tico" estritamente a passo de formiga. Evita saltos cegos fora do abismo, preservando as detec√ß√µes finas da Fraude dilu√≠da. |

### 12.3.2 M√°quinas de Gradient Boosting (`XGBClassifier` & `LGBMClassifier`)

> **üü¢ Resultados Pr√°ticos:** Consagra√ß√£o do *Hype* tabulado do Aprendizado de M√°quina Competitivo atual. Dom√≠nio ostensivo Absoluto das m√©tricas focadas nos cen√°rios de despropor√ß√£o assim√©trica (`LGBM: F1 = 0.231, PR_AUC = 0.158` / `XGB: F1 = 0.231, PR_AUC = 0.153`). Limites de bloqueio otimizados na margem probabil√≠stica cravada em torno dos `0.88` aos `0.89`.

* **A Ess√™ncia do Sucesso (Boosting Sequencial Te√≥rico):** Contrastando radicalmente perante a Natureza Aleat√≥ria de "M√©dia Popular" gerada em paridade das √Årvores Bagging, estes motores geram √°rvores estritamente encadeadas no espa√ßo-tempo. A √Årvore subsequente constr√≥i-se focando seu Gradiente puramente nos Res√≠duos (O erro cont√≠nuo). Elas perseguem de forma predat√≥ria os `"Erros Complexos"` ‚Äî a parcela elitista de fraudadores avan√ßados que despistam todas as avalia√ß√µes rasas ‚Äî alocando neles pesos gigantes de penaliza√ß√£o for√ßat√≥ria.

**Engenharia de Par√¢metros Implementados:**

| Par√¢metro | Valores Testados | Conceito e Impacto |
| :--- | :--- | :--- |
| `learning_rate` & `n_estimators` | `0.03 - 0.10` <br> & <br> `100 - 500` | **Taxa do Gradiente e Passos Temporais.** Formam uma Superf√≠cie Suave de Resgate. Ao criar centenas de √°rvores que aprendem parcelas min√∫sculas (ex: 3%) do erro anterior, evitamos radicalismos, refinando a complexidade progressiva sem queimar poder de an√°lise num passo s√≥. |
| `reg_alpha` & `reg_lambda` | `0.01` (L1) <br> & <br> `5.0` (L2) | **Fun√ß√µes de regulariza√ß√£o matem√°ticas.** Elas destroem e imp√µem taxa√ß√µes mortais sobre galhos profundos soltos hiper espec√≠ficos, castrando decorismos e propiciando defesas Anti-Explosivas no Teste Org√¢nico cego. |
| `subsample` & `colsample_bytree` | `0.6 - 0.7` | **Amostragem Fracionada Bidimensional.** Ditam a pureza do cegamento. A cada nova √°rvore, o algoritmo √© amorda√ßado para enxergar unicamente 60% das Colunas rand√¥micas e 60% dos Clientes. Isso adestra a rede a identificar padr√µes subentendidos, enfraquecendo a "Super-Depend√™ncia" em colunas campe√£s. |