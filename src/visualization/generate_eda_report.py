import sys
import io
import pandas as pd
import numpy as np
# Fix de compatibilidade: Sweetviz ainda usa VisibleDeprecationWarning removido no Numpy 2.0+
if not hasattr(np, "VisibleDeprecationWarning"):
    np.VisibleDeprecationWarning = UserWarning

import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from scipy.stats import mannwhitneyu
from sklearn.feature_selection import mutual_info_classif

# ==============================================================================
# ARQUIVO: generate_eda_report.py
#
# OBJETIVO:
#   Automatizar a gera√ß√£o de relat√≥rios de An√°lise Explorat√≥ria de Dados (EDA).
#   O script carrega os dados brutos, calcula estat√≠sticas descritivas,
#   gera visualiza√ß√µes (distribui√ß√µes, correla√ß√µes, risco por categoria) e
#   exporta um resumo textual, tabelas CSV e report HTML para an√°lise.
#
# PARTE DO SISTEMA:
#   M√≥dulo de Visualiza√ß√£o e An√°lise de Dados (Preprocessing Stage).
#
# RESPONSABILIDADES:
#   - Carregar e validar o dataset inicial.
#   - Identificar automaticamente colunas num√©ricas, categ√≥ricas e o target.
#   - Gerar m√©tricas de qualidade de dados (nulos, tipos, cardinalidade, duplicatas).
#   - Realizar testes estat√≠sticos (Mann-Whitney) e quantifica√ß√£o de outliers (IQR).
#   - Produzir artefatos visuais (gr√°ficos) salvos em 'reports/figures/eda'.
#   - Produzir artefatos de dados (CSVs estat√≠sticos) salvos em 'reports/data'.
#   - Produzir artefato textual (relat√≥rio) salvo em 'reports/eda_summary.txt'.
#   - Gerar dashboard interativo HTML (Sweetviz) salvo em 'reports/sweetviz_report.html'.
#
# COMUNICA√á√ÉO:
#   - L√™: data/raw/Base.csv (padr√£o ou configurado no config.py)
#   - Escreve: reports/figures/eda/* (PNGs das an√°lises)
#   - Escreve: reports/data/*.csv (Tabelas de m√©tricas para persist√™ncia)
#   - Escreve: reports/eda_summary.txt (Relat√≥rio consolidado)
#   - Escreve: reports/sweetviz_report.html (Dashboard interativo)
# ==============================================================================

# Adiciona raiz ao path para garantir que imports do pacote 'src' funcionem
PROJECT_ROOT = Path(__file__).resolve().parents[2]
sys.path.append(str(PROJECT_ROOT))

# Tenta importar configura√ß√µes centralizadas; define fallback para execu√ß√£o isolada
try:
    from src.config import RAW_DATA_PATH, FIGURES_DIR, REPORTS_DIR
except ImportError:
    # Caminhos padr√£o caso o script seja executado fora do contexto do pacote principal
    RAW_DATA_PATH = PROJECT_ROOT / "data" / "raw" / "Base.csv"
    FIGURES_DIR = PROJECT_ROOT / "reports" / "figures"
    REPORTS_DIR = PROJECT_ROOT / "reports"

# Configura√ß√µes Globais de Sa√≠da
EDA_OUTPUT_DIR = FIGURES_DIR / "eda"
EDA_DATA_DIR = REPORTS_DIR / "data"  # Diret√≥rio para persist√™ncia de CSVs
EDA_REPORT_FILE = REPORTS_DIR / "eda_summary.txt"

# Configura√ß√µes Est√©ticas de Plotagem (Seaborn/Matplotlib)
sns.set_theme(style="whitegrid", context="paper")
plt.rcParams["figure.figsize"] = (12, 6)

class EDAReporter:
    """
    Classe respons√°vel por orquestrar toda a an√°lise explorat√≥ria.
    Encapsula o estado dos dados, configura√ß√µes de diret√≥rio e l√≥gica de gera√ß√£o de relat√≥rios.
    """
    
    def __init__(self, data_path):
        """
        Inicializa o reporter com o caminho dos dados.
        
        - O que recebe:
          data_path (str/Path): Caminho para o arquivo CSV de dados brutos.
          Ex: 'data/raw/Base.csv'
        - O que retorna: Inst√¢ncia de Si Mesmo.
        - Quando √© chamada: Imediatamente antes de invocar o `.run()` no pipeline principal.
        """
        self.data_path = Path(data_path)
        self.df = None
        self.target_col = None
        self.num_cols = []
        self.cat_cols = []
        self.report_buffer = io.StringIO() # Buffer em mem√≥ria para construir o relat√≥rio texto incrementalmente

    def _log(self, title, content):
        """
        M√©todo auxiliar para registrar uma se√ß√£o no buffer do relat√≥rio textual e imprimir feedback no console.
        
        Args:
            title (str): T√≠tulo da se√ß√£o (ex: "Estat√≠sticas Descritivas").
            content (str): Corpo do texto ou representa√ß√£o string de um DataFrame.
        """
        self.report_buffer.write(f"\n{'='*80}\n")
        self.report_buffer.write(f" {title.upper()}\n")
        self.report_buffer.write(f"{'='*80}\n")
        self.report_buffer.write(f"{content}\n")
        print(f"‚úÖ [Processado]: {title}")

    def setup_directories(self):
        """
        Garante que os diret√≥rios de sa√≠da (imagens, dados, relat√≥rios) existam antes de salvar arquivos.
        Utiliza 'mkdir(parents=True)' para criar caminhos aninhados se necess√°rio.
        """
        EDA_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
        EDA_DATA_DIR.mkdir(parents=True, exist_ok=True)
        REPORTS_DIR.mkdir(parents=True, exist_ok=True)

    def load_data(self):
        """
        Carrega o dataset e realiza a introspec√ß√£o inicial das colunas.
        
        L√≥gica:
            1. Carrega o CSV apontado pelo Path.
            2. Identifica automaticamente a coluna alvo (target) buscando por nomes comuns em fraude.
            3. Segrega colunas em listas de Num√©ricas e Categ√≥ricas para processamento diferenciado.
            4. Remove o target da lista de features num√©ricas para evitar redund√¢ncia/vazamento nos gr√°ficos.
        """
        if not self.data_path.exists():
            raise FileNotFoundError(f"Arquivo n√£o encontrado: {self.data_path}")
        
        self.df = pd.read_csv(self.data_path)
        
        # Identifica√ß√£o autom√°tica do target (Regra de Neg√≥cio: suporta nomenclaturas padr√£o de datasets de fraude)
        if 'fraud_bool' in self.df.columns:
            self.target_col = 'fraud_bool'
        elif 'is_fraud' in self.df.columns:
            self.target_col = 'is_fraud'
        
        # Separa√ß√£o de Colunas por Tipo
        self.cat_cols = self.df.select_dtypes(include=['object', 'category', 'string']).columns.tolist()
        self.num_cols = self.df.select_dtypes(include=['number']).columns.tolist()
        
        # Ajuste estrat√©gico: O target n√£o deve ser tratado como feature num√©rica comum nas an√°lises de input
        if self.target_col and self.target_col in self.num_cols:
            self.num_cols.remove(self.target_col)

        self._log("Carga de Dados", f"Dataset carregado: {self.df.shape}\nTarget: {self.target_col}")

    def generate_structure_report(self):
        """
        Gera m√©tricas de qualidade e estrutura dos dados para identificar problemas iniciais.
        
        An√°lises realizadas:
            - Tipos de dados e uso de mem√≥ria (df.info).
            - Contagem e percentual de nulos por coluna.
            - Cardinalidade (valores √∫nicos) para detectar constantes ou IDs.
            - Detec√ß√£o de linhas duplicadas (integridade do dado).
            
        Persist√™ncia:
            - Salva a tabela de qualidade em 'reports/data/data_quality.csv'.
        """
        # Captura o output do df.info() que normalmente vai para o console
        buffer = io.StringIO()
        self.df.info(buf=buffer, verbose=True, show_counts=True)
        info_str = buffer.getvalue()
        
        # Cria DataFrame resumo de qualidade
        quality = pd.DataFrame({
            'Dtype': self.df.dtypes,
            'Nulos': self.df.isnull().sum(),
            '% Nulos': (self.df.isnull().sum() / len(self.df)) * 100,
            'Cardinalidade': self.df.nunique()
        }).sort_values(by='% Nulos', ascending=False)

        # Verifica√ß√£o de Duplicatas
        n_duplicates = self.df.duplicated().sum()
        dup_pct = (n_duplicates / len(self.df)) * 100
        dup_msg = f"Duplicatas: {n_duplicates} ({dup_pct:.2f}%)"

        # PERSIST√äNCIA: Salva em CSV para consumo posterior
        quality.to_csv(EDA_DATA_DIR / "data_quality.csv")

        report_content = f"{info_str}\n\n--- RELAT√ìRIO DE QUALIDADE ---\n{dup_msg}\n\n{quality.to_string()}"
        self._log("Estrutura e Qualidade", report_content)

    def analyze_categorical_domain(self):
        """
        Analisa o dom√≠nio das vari√°veis categ√≥ricas.
        
        L√≥gica:
            - Para baixa cardinalidade (<= 30): Lista todos os valores √∫nicos (√∫til para entender categorias como 'status', 'type').
            - Para alta cardinalidade: Lista apenas o Top 5 mais frequentes para evitar polui√ß√£o visual.
        """
        buffer_str = ""
        for col in self.cat_cols:
            unique_vals = self.df[col].unique()
            if len(unique_vals) <= 30:
                buffer_str += f"\nFeature '{col}' ({len(unique_vals)} categorias):\n   {sorted(unique_vals, key=lambda x: str(x))}\n"
            else:
                top_5 = self.df[col].value_counts().head(5).index.tolist()
                buffer_str += f"\nFeature '{col}': Alta cardinalidade ({len(unique_vals)} √∫nicos). Top 5 mais frequentes: {top_5}...\n"
        
        self._log("Dom√≠nio das Vari√°veis Categ√≥ricas", buffer_str)

    def analyze_outliers(self):
        """
        Quantifica outliers usando o m√©todo estat√≠stico IQR (Interquartile Range).
        
        Regra:
            - Outlier Inferior < Q1 - 1.5 * IQR
            - Outlier Superior > Q3 + 1.5 * IQR
            
        Persist√™ncia:
            - Salva a tabela de contagem de outliers em 'reports/data/outliers_iqr.csv'.
            
        Objetivo:
            - Alertar sobre a necessidade de tratamento (remo√ß√£o ou capping) antes da modelagem.
        """
        outlier_report = []
        
        for col in self.num_cols:
            Q1 = self.df[col].quantile(0.25)
            Q3 = self.df[col].quantile(0.75)
            IQR = Q3 - Q1
            
            # Limites te√≥ricos comuns
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            n_outliers = ((self.df[col] < lower_bound) | (self.df[col] > upper_bound)).sum()
            pct_outliers = (n_outliers / len(self.df)) * 100
            
            outlier_report.append({
                'Feature': col,
                'Outliers': n_outliers,
                '% Outliers': pct_outliers,
                'Lower Bound': lower_bound,
                'Upper Bound': upper_bound
            })
            
        if outlier_report:
            outlier_df = pd.DataFrame(outlier_report).sort_values(by='% Outliers', ascending=False)
            
            # PERSIST√äNCIA
            outlier_df.to_csv(EDA_DATA_DIR / "outliers_iqr.csv", index=False)
            
            self._log("Quantifica√ß√£o de Outliers (IQR Method)", outlier_df.to_string())

    def generate_statistics_report(self):
        """
        Calcula estat√≠sticas descritivas b√°sicas (m√©dia, desvio padr√£o, quartis).
        Essencial para entender a escala ("ordem de grandeza") e dispers√£o das vari√°veis num√©ricas.
        
        Persist√™ncia:
            - Salva em 'reports/data/descriptive_statistics.csv'.
        """
        desc = self.df.describe().T
        # PERSIST√äNCIA
        desc.to_csv(EDA_DATA_DIR / "descriptive_statistics.csv")
        self._log("Estat√≠sticas Descritivas (Num√©ricas)", desc.to_string())

    def perform_statistical_tests(self):
        """
        Realiza testes de hip√≥tese (Mann-Whitney U) para verificar signific√¢ncia estat√≠stica.
        
        Objetivo:
            - Validar se a distribui√ß√£o de uma feature √© estatisticamente diferente entre 'Fraude' e 'Genu√≠no'.
            - Se p-value < 0.05, rejeita-se a nulidade: a feature PROVAVELMENTE ajuda a separar fraude.
        
        Por que Mann-Whitney?
            - √â um teste n√£o-param√©trico (n√£o assume distribui√ß√£o Normal), ideal para dados financeiros 
              que costumam ter caudas longas e outliers.

        Persist√™ncia:
            - Salva em 'reports/data/statistical_tests_mann_whitney.csv'.
        """
        if not self.target_col: return

        results = []
        # Separa os grupos
        fraud_data = self.df[self.df[self.target_col] == 1]
        legit_data = self.df[self.df[self.target_col] == 0]

        # Amostragem para performance se o dataset for massivo (>100k linhas)
        # O teste √© O(n*m), ent√£o amostras de 10k j√° d√£o signific√¢ncia com performance
        if len(self.df) > 100000:
             fraud_sample = fraud_data.sample(min(len(fraud_data), 10000), random_state=42)
             legit_sample = legit_data.sample(min(len(legit_data), 10000), random_state=42)
        else:
             fraud_sample = fraud_data
             legit_sample = legit_data

        for col in self.num_cols:
            # Mann-Whitney U test (two-sided)
            stat, p_value = mannwhitneyu(fraud_sample[col], legit_sample[col], alternative='two-sided')
            
            significancia = "Significativo (p<0.05)" if p_value < 0.05 else "N√£o Significativo"
            results.append({
                'Feature': col,
                'Mann-Whitney Stat': stat,
                'P-Value': p_value,
                'Conclus√£o': significancia
            })
            
        stats_df = pd.DataFrame(results).sort_values(by='P-Value')
        
        # PERSIST√äNCIA
        stats_df.to_csv(EDA_DATA_DIR / "statistical_tests_mann_whitney.csv", index=False)
        
        self._log("Testes Estat√≠sticos (Fraude vs Legit)", stats_df.to_string())

    def calculate_mutual_information(self):
        """
        Calcula o Score de Informa√ß√£o M√∫tua (Mutual Information) entre features e o target.
        
        Diferen√ßa vs Correla√ß√£o:
            - Correla√ß√£o mede rela√ß√£o Linear/Monot√¥nica.
            - Mutual Info mede QUALQUER depend√™ncia (ex: rela√ß√£o quadr√°tica, senoidal, complexa).
            
        Import√¢ncia:
            - Features com alta MI s√£o candidatas fortes para o modelo, mesmo se a correla√ß√£o for baixa.
            
        Persist√™ncia:
            - Salva rankings em 'reports/data/mutual_information_scores.csv'.
            - Salva gr√°fico em 'reports/figures/eda/05_mutual_information.png'.
        """
        if not self.target_col: return

        # Amostragem para performance (MI √© muito custoso computacionalmente com KNN interno)
        sample_size = min(50000, len(self.df))
        df_sample = self.df.sample(sample_size, random_state=42)
        
        X = df_sample[self.num_cols].fillna(0) # MI do sklearn n√£o aceita NaNs
        y = df_sample[self.target_col]

        mi_scores = mutual_info_classif(X, y, discrete_features=False, random_state=42)
        mi_df = pd.DataFrame({'Feature': self.num_cols, 'MI Score': mi_scores})
        mi_df = mi_df.sort_values(by='MI Score', ascending=False)

        # Plot
        plt.figure(figsize=(10, 8))
        # Fix FutureWarning: Assign y to hue
        sns.barplot(x=mi_df['MI Score'], y=mi_df['Feature'], hue=mi_df['Feature'], palette='viridis', legend=False)
        plt.title("Mutual Information Score (Top Features)")
        plt.tight_layout()
        plt.savefig(EDA_OUTPUT_DIR / "05_mutual_information.png")
        plt.close()

        self._log("Mutual Information (Import√¢ncia de Features)", mi_df.to_string())
        
        # PERSIST√äNCIA
        mi_df.to_csv(EDA_DATA_DIR / "mutual_information_scores.csv", index=False)

    def plot_comparative_boxplots(self):
        """
        Gera Boxplots comparativos (Fraude vs N√£o Fraude) para vari√°veis num√©ricas.
        
        Visualiza√ß√£o:
            - Eixo X: Classes (0 e 1).
            - Eixo Y: Valor da Feature (Log Scale).
            
        Objetivo:
            - Visualizar se existe separa√ß√£o visual clara entre as classes.
            - Verificar se fraudes tendem a ter valores maiores/menores ou mais vari√¢ncia.
            - Usa escala sim√©trica logar√≠tmica (symlog) para lidar com dados financeiros distorcidos.
        """
        if not self.target_col: return

        # Seleciona features limitadas para o grid n√£o ficar gigante (Top 12 da lista original)
        cols_to_plot = self.num_cols[:12] 
        n_cols = 3
        n_rows = (len(cols_to_plot) // n_cols) + 1

        # Prepara√ß√£o para plotagem: Map target to string labels to avoid Matplotlib warnings
        df_plot = self.df.copy()
        df_plot[self.target_col] = df_plot[self.target_col].replace({0: 'Genu√≠no', 1: 'Fraude'})

        plt.figure(figsize=(18, 5 * n_rows))
        
        for i, col in enumerate(cols_to_plot):
            plt.subplot(n_rows, n_cols, i+1)
            # Fix FutureWarning: Assign x to hue
            sns.boxplot(x=self.target_col, y=col, data=df_plot, hue=self.target_col, palette='Set2', legend=False)
            plt.title(f"{col} por Classe")
            plt.yscale('symlog') 
        
        plt.tight_layout()
        plt.savefig(EDA_OUTPUT_DIR / "06_comparative_boxplots.png")
        plt.close()

    def plot_temporal_analysis(self):
        """
        Analisa a taxa de fraude ao longo do tempo (apenas se houver coluna 'month').
        
        Objetivo:
            - Detectar sazonalidade (ex: fraude aumenta no natal?) ou tend√™ncias (ataque crescendo?).
        """
        if 'month' in self.df.columns and self.target_col:
            fraud_by_month = self.df.groupby('month')[self.target_col].mean()
            
            plt.figure(figsize=(10, 6))
            sns.lineplot(x=fraud_by_month.index, y=fraud_by_month.values, marker='o', color='crimson')
            plt.title("Taxa de Fraude por M√™s (Sazonalidade)")
            plt.ylabel("Taxa de Fraude (M√©dia)")
            plt.xlabel("M√™s")
            plt.grid(True)
            plt.savefig(EDA_OUTPUT_DIR / "07_temporal_fraud_rate.png")
            plt.close()
            
            self._log("An√°lise Temporal", f"Taxa de Fraude por M√™s:\n{fraud_by_month.to_string()}")

    def plot_target_distribution(self):
        """
        Visualiza o balanceamento das classes de fraude.
        
        Objetivo:
            - Mostrar graficamente e textualmente o qu√£o desbalanceado √© o dataset.
            - Essencial para definir m√©tricas de avalia√ß√£o (evitar Acur√°cia em datasets 99% vs 1%).
        """
        if not self.target_col: return

        # Prepara√ß√£o para plotagem: Map target to string labels
        df_plot = self.df.copy()
        df_plot[self.target_col] = df_plot[self.target_col].replace({0: 'Genu√≠no', 1: 'Fraude'})

        plt.figure(figsize=(8, 5))
        ax = sns.countplot(x=self.target_col, data=df_plot, palette='viridis', hue=self.target_col, legend=False)
        plt.title(f"Distribui√ß√£o do Target: {self.target_col}")
        
        # Calcula propor√ß√µes
        count = self.df[self.target_col].value_counts()
        pct = self.df[self.target_col].value_counts(normalize=True) * 100
        self._log("Distribui√ß√£o do Target", pd.DataFrame({'Total': count, '%': pct}).to_string())

        plt.tight_layout()
        plt.savefig(EDA_OUTPUT_DIR / "01_target_distribution.png")
        plt.close()

    def plot_correlations(self):
        """
        Gera e salva a matriz de correla√ß√£o (Spearman) entre vari√°veis num√©ricas.
        
        Decis√£o T√©cnica:
            - Utiliza 'Spearman' (rank-order) em vez de Pearson.
            - Motivo: Dados de fraude raramente s√£o lineares/normais. Spearman captura rela√ß√µes monot√¥nicas.
            
        Persist√™ncia:
            - Salva matriz completa em 'reports/data/correlation_matrix.csv'.
            - Filtra e exibe no log textual as features mais correlacionadas com o target.
        """
        corr = self.df[self.num_cols + [self.target_col]].corr(method='spearman')
        
        # Plot do Heatmap
        plt.figure(figsize=(16, 12))
        mask = np.triu(np.ones_like(corr, dtype=bool)) # M√°scara para limpar a diagonal superior (√© espelhada)
        sns.heatmap(corr, mask=mask, cmap='RdBu_r', center=0, square=True, linewidths=.5, cbar_kws={"shrink": .5})
        plt.title("Matriz de Correla√ß√£o (Spearman)")
        plt.savefig(EDA_OUTPUT_DIR / "02_correlation_matrix.png")
        plt.close()

        # PERSIST√äNCIA
        corr.to_csv(EDA_DATA_DIR / "correlation_matrix.csv")

        # Texto: Identifica e loga features com maior correla√ß√£o absoluta com fraude
        if self.target_col:
            target_corr = corr[self.target_col].sort_values(ascending=False)
            self._log("Correla√ß√µes com o Target", target_corr.to_string())

    def plot_all_histograms(self):
        """
        Gera histogramas para TODAS as colunas num√©ricas em formato de grid.
        
        Objetivo:
            - Vis√£o panor√¢mica (Big Picture) das distribui√ß√µes.
            - R√°pida identifica√ß√£o visual de caudas longas, bimodais ou dados concentrados.
        """
        n_cols = len(self.num_cols)
        n_rows = (n_cols // 4) + 1
        
        plt.figure(figsize=(20, 4 * n_rows))
        
        for i, col in enumerate(self.num_cols):
            plt.subplot(n_rows, 4, i+1)
            data_to_plot = self.df[col]
            sns.histplot(x=data_to_plot, bins=30, kde=False, color='steelblue', edgecolor='black', linewidth=0.5)
            plt.title(col, fontsize=10)
            plt.xlabel("")
        
        plt.tight_layout()
        plt.savefig(EDA_OUTPUT_DIR / "03_all_numerical_distributions.png")
        plt.close()

    def plot_categorical_risks(self):
        """
        Analisa o Risco Relativo (Taxa de Fraude) por categoria.
        
        L√≥gica:
            - Agrupa por categoria e calcula a m√©dia do target (0 a 1).
            - M√©dia 0.05 significa 5% de fraude naquela categoria.
            - Filtra categorias com cardinalidade > 50 para o gr√°fico n√£o quebrar/ficar ileg√≠vel.
        """
        buffer_cats = ""
        
        for col in self.cat_cols:
            # Regra de Visualiza√ß√£o: Ignora alta cardinalidade
            if self.df[col].nunique() > 50: continue

            # C√°lculo do Risco
            risk = self.df.groupby(col)[self.target_col].mean().sort_values(ascending=False)
            buffer_cats += f"\n--- Risco por {col} ---\n{risk.to_string()}\n"

            # Plotagem
            plt.figure(figsize=(12, 6))
            sns.barplot(x=risk.index, y=risk.values, palette='magma', hue=risk.index, legend=False)
            plt.title(f"Risco de Fraude por {col}")
            plt.xticks(rotation=45)
            plt.tight_layout()
            plt.savefig(EDA_OUTPUT_DIR / f"04_risk_{col}.png")
            plt.close()
            
        self._log("An√°lise de Risco Categ√≥rico", buffer_cats)

    def generate_interactive_report(self):
        """
        Gera um relat√≥rio HTML interativo avan√ßado utilizando a biblioteca Sweetviz.
        
        O que ele faz:
            - Cria um arquivo .html standalone (offline) com dashboard interativo.
            - Compara distribui√ß√µes do Target (Fraude vs N√£o Fraude) lado a lado em todas as features.
            - Mostra nulos, valores distintos e estat√≠sticas in-place.
            
        Observa√ß√£o:
            - Requer a biblioteca 'sweetviz' instalada. 
            - O try/except garante que a execu√ß√£o n√£o quebre se o usu√°rio n√£o tiver a lib.
        """
        print("üìä Tentando importar sweetviz...")
        try:
            import sweetviz as sv
            print("‚úÖ Import realizado com sucesso!")
            
            print("üìä Gerando relat√≥rio interativo com Sweetviz (pode demorar um pouco)...")
            
            # Se tivermos target, configuramos para ele comparar as distribui√ß√µes "Target=0 vs Target=1"
            if self.target_col:
                report = sv.analyze([self.df, "Training Data"], target_feat=self.target_col)
            else:
                report = sv.analyze([self.df, "Training Data"])
                
            html_path = REPORTS_DIR / "sweetviz_report.html"
            report.show_html(filepath=str(html_path), open_browser=False)
            print(f"‚úÖ Relat√≥rio Interativo HTML salvo em: {html_path}")
            
        except ImportError:
             print("\n‚ö†Ô∏è Sweetviz n√£o encontrado. Instale com 'pip install sweetviz' para habilitar o dashboard HTML.")
        except Exception as e:
             print(f"\n‚ùå Erro na gera√ß√£o do relat√≥rio Sweetviz: {e}")

    def save_report(self):
        """
        Persiste o conte√∫do textual acumulado (self.report_buffer) no disco.
        """
        with open(EDA_REPORT_FILE, "w", encoding="utf-8") as f:
            f.write(self.report_buffer.getvalue())
        print(f"\nüìÑ Relat√≥rio de Texto salvo em: {EDA_REPORT_FILE}")
        print(f"üñºÔ∏è Gr√°ficos salvos em: {EDA_OUTPUT_DIR}")

    def run(self):
        """
        Orquestrador principal (Pipeline de Execu√ß√£o).
        Define a ordem l√≥gica das an√°lises: Setup -> Carga -> Estrutura -> Estat√≠stica -> Visualiza√ß√£o.
        """
        print("üöÄ Iniciando An√°lise Explorat√≥ria Automatizada (Modo Avan√ßado)...")
        self.setup_directories()
        self.load_data()
        
        # Etapa 1: Entendimento dos Dados (Data Understanding)
        self.generate_structure_report()
        self.analyze_categorical_domain()
        self.generate_statistics_report()
        self.analyze_outliers()
        self.plot_target_distribution()
        
        # Etapa 2: An√°lises de Correla√ß√£o e Causalidade
        if self.target_col:
            # An√°lises Avan√ßadas (Acad√™mico/Profissional)
            self.perform_statistical_tests()
            self.calculate_mutual_information()
            self.plot_comparative_boxplots()
            self.plot_temporal_analysis()

        # Etapa 3: Visualiza√ß√µes Gerais
        self.plot_correlations()
        self.plot_all_histograms()
        
        if self.target_col:
            self.plot_categorical_risks()
            
        # Etapa 4: Dashboard Interativo (Output Rico)
        self.generate_interactive_report()
            
        # Finaliza√ß√£o
        self.save_report()
        print("üèÅ An√°lise Conclu√≠da com Sucesso!")

if __name__ == "__main__":
    # Configura pandas para n√£o truncar colunas/linhas na impress√£o do console/relat√≥rio
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', 1000)
    
    reporter = EDAReporter(RAW_DATA_PATH)
    reporter.run()